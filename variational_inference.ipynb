{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "ac2159a4-040f-4a74-b47e-e6ffb9054d41",
      "metadata": {
        "id": "ac2159a4-040f-4a74-b47e-e6ffb9054d41"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from enum import Enum\n",
        "import torch\n",
        "from tqdm import tqdm\n",
        "from torch import nn\n",
        "from torch.nn import functional as F, init\n",
        "from torch import optim\n",
        "import torch.distributions as dist\n",
        "import time\n",
        "import shutil\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "906a6e98-9fb4-4ca0-95f3-4eebf4302df1",
      "metadata": {
        "id": "906a6e98-9fb4-4ca0-95f3-4eebf4302df1"
      },
      "outputs": [],
      "source": [
        "ROOT_DIR = os.path.realpath('./')\n",
        "DATA_DIR = os.path.join(ROOT_DIR, 'data')\n",
        "EDNET_KT1_DIR = os.path.join(DATA_DIR, 'ednet_kt1')\n",
        "OUT_DIR = os.path.join(ROOT_DIR, 'out')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r7ephw14PB1R",
        "outputId": "46c333d1-159e-4ded-9307-adbf8de7146a"
      },
      "id": "r7ephw14PB1R",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "EDNET_KT1_DIR = '/content/drive/MyDrive/kt1'\n",
        "OUT_DIR = '/content/drive/MyDrive/kt1'"
      ],
      "metadata": {
        "id": "AL3H8dpRO_BV"
      },
      "id": "AL3H8dpRO_BV",
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "3b760dd0-ef68-4c3a-a64c-10d28e414a42",
      "metadata": {
        "id": "3b760dd0-ef68-4c3a-a64c-10d28e414a42"
      },
      "outputs": [],
      "source": [
        "MISSING_DATA = -1"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e0e71ec9-90a5-4072-99e6-d2fff3ab5314",
      "metadata": {
        "id": "e0e71ec9-90a5-4072-99e6-d2fff3ab5314"
      },
      "source": [
        "# Data Exploration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a8e64c5e-5f26-4e49-9313-c262429a9e69",
      "metadata": {
        "id": "a8e64c5e-5f26-4e49-9313-c262429a9e69",
        "outputId": "8d0bacce-441b-4a55-a978-8b7108db3458"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>timestamp</th>\n",
              "      <th>solving_id</th>\n",
              "      <th>question_id</th>\n",
              "      <th>user_answer</th>\n",
              "      <th>elapsed_time</th>\n",
              "      <th>user_id</th>\n",
              "      <th>bundle_id</th>\n",
              "      <th>explanation_id</th>\n",
              "      <th>correct_answer</th>\n",
              "      <th>part</th>\n",
              "      <th>tags</th>\n",
              "      <th>deployed_at</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1552405824275</td>\n",
              "      <td>1</td>\n",
              "      <td>q5713</td>\n",
              "      <td>a</td>\n",
              "      <td>24000</td>\n",
              "      <td>u533092</td>\n",
              "      <td>b4245</td>\n",
              "      <td>e4245</td>\n",
              "      <td>a</td>\n",
              "      <td>5</td>\n",
              "      <td>71</td>\n",
              "      <td>1568635574409</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1552405824275</td>\n",
              "      <td>1</td>\n",
              "      <td>q5713</td>\n",
              "      <td>a</td>\n",
              "      <td>24000</td>\n",
              "      <td>u533092</td>\n",
              "      <td>b4245</td>\n",
              "      <td>e4245</td>\n",
              "      <td>a</td>\n",
              "      <td>5</td>\n",
              "      <td>71</td>\n",
              "      <td>1568635574409</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       timestamp  solving_id question_id user_answer  elapsed_time  user_id  \\\n",
              "0  1552405824275           1       q5713           a         24000  u533092   \n",
              "1  1552405824275           1       q5713           a         24000  u533092   \n",
              "\n",
              "  bundle_id explanation_id correct_answer  part tags    deployed_at  \n",
              "0     b4245          e4245              a     5   71  1568635574409  \n",
              "1     b4245          e4245              a     5   71  1568635574409  "
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def preprocess(dataset_file_name):\n",
        "    cache_file = os.path.join(EDNET_KT1_DIR, dataset_file_name)\n",
        "    if os.path.isfile(cache_file):\n",
        "        return pd.read_csv(cache_file)\n",
        "    \n",
        "    responses = pd.read_csv(os.path.join(EDNET_KT1_DIR, f'unprocessed/{dataset_name}'))\n",
        "    responses = responses[['timestamp', 'solving_id', 'question_id', 'user_answer', 'elapsed_time', 'user_id']]\n",
        "    \n",
        "    questions = pd.read_csv(os.path.join(EDNET_KT1_DIR, 'contents/questions.csv'))\n",
        "    \n",
        "    joined = pd.merge(responses, questions, how='inner', on=['question_id'])\n",
        "    assert joined.shape[0] == responses.shape[0]\n",
        "    \n",
        "    joined.to_csv(cache_file, index=False)\n",
        "    \n",
        "    return joined\n",
        "\n",
        "dataset_name = 'kt1_subset.csv'\n",
        "raw_data = preprocess(dataset_name)\n",
        "raw_data.head(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "62e6695c-aa79-4d96-81d3-d30be209276d",
      "metadata": {
        "id": "62e6695c-aa79-4d96-81d3-d30be209276d",
        "outputId": "4a74f651-83eb-4276-a80a-912fee3e2652"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>timestamp</th>\n",
              "      <th>solving_id</th>\n",
              "      <th>question_id</th>\n",
              "      <th>user_answer</th>\n",
              "      <th>elapsed_time</th>\n",
              "      <th>user_id</th>\n",
              "      <th>bundle_id</th>\n",
              "      <th>explanation_id</th>\n",
              "      <th>correct_answer</th>\n",
              "      <th>part</th>\n",
              "      <th>tags</th>\n",
              "      <th>deployed_at</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1552405824275</td>\n",
              "      <td>1</td>\n",
              "      <td>q5713</td>\n",
              "      <td>a</td>\n",
              "      <td>24000</td>\n",
              "      <td>u533092</td>\n",
              "      <td>b4245</td>\n",
              "      <td>e4245</td>\n",
              "      <td>a</td>\n",
              "      <td>5</td>\n",
              "      <td>71</td>\n",
              "      <td>1568635574409</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1552405824275</td>\n",
              "      <td>1</td>\n",
              "      <td>q5713</td>\n",
              "      <td>a</td>\n",
              "      <td>24000</td>\n",
              "      <td>u533092</td>\n",
              "      <td>b4245</td>\n",
              "      <td>e4245</td>\n",
              "      <td>a</td>\n",
              "      <td>5</td>\n",
              "      <td>71</td>\n",
              "      <td>1568635574409</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1540785188092</td>\n",
              "      <td>2</td>\n",
              "      <td>q5713</td>\n",
              "      <td>a</td>\n",
              "      <td>15000</td>\n",
              "      <td>u298664</td>\n",
              "      <td>b4245</td>\n",
              "      <td>e4245</td>\n",
              "      <td>a</td>\n",
              "      <td>5</td>\n",
              "      <td>71</td>\n",
              "      <td>1568635574409</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1559943082762</td>\n",
              "      <td>17</td>\n",
              "      <td>q5713</td>\n",
              "      <td>a</td>\n",
              "      <td>8000</td>\n",
              "      <td>u608719</td>\n",
              "      <td>b4245</td>\n",
              "      <td>e4245</td>\n",
              "      <td>a</td>\n",
              "      <td>5</td>\n",
              "      <td>71</td>\n",
              "      <td>1568635574409</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1535867868674</td>\n",
              "      <td>246</td>\n",
              "      <td>q5713</td>\n",
              "      <td>a</td>\n",
              "      <td>34000</td>\n",
              "      <td>u248874</td>\n",
              "      <td>b4245</td>\n",
              "      <td>e4245</td>\n",
              "      <td>a</td>\n",
              "      <td>5</td>\n",
              "      <td>71</td>\n",
              "      <td>1568635574409</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1048570</th>\n",
              "      <td>1541769524423</td>\n",
              "      <td>420</td>\n",
              "      <td>q6827</td>\n",
              "      <td>d</td>\n",
              "      <td>22750</td>\n",
              "      <td>u295354</td>\n",
              "      <td>b5183</td>\n",
              "      <td>e5183</td>\n",
              "      <td>d</td>\n",
              "      <td>6</td>\n",
              "      <td>179;143</td>\n",
              "      <td>1564124620642</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1048571</th>\n",
              "      <td>1503686797917</td>\n",
              "      <td>2470</td>\n",
              "      <td>q6827</td>\n",
              "      <td>c</td>\n",
              "      <td>61000</td>\n",
              "      <td>u21819</td>\n",
              "      <td>b5183</td>\n",
              "      <td>e5183</td>\n",
              "      <td>d</td>\n",
              "      <td>6</td>\n",
              "      <td>179;143</td>\n",
              "      <td>1564124620642</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1048572</th>\n",
              "      <td>1534224187825</td>\n",
              "      <td>244</td>\n",
              "      <td>q6827</td>\n",
              "      <td>d</td>\n",
              "      <td>48250</td>\n",
              "      <td>u38390</td>\n",
              "      <td>b5183</td>\n",
              "      <td>e5183</td>\n",
              "      <td>d</td>\n",
              "      <td>6</td>\n",
              "      <td>179;143</td>\n",
              "      <td>1564124620642</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1048573</th>\n",
              "      <td>1518238277613</td>\n",
              "      <td>897</td>\n",
              "      <td>q6827</td>\n",
              "      <td>d</td>\n",
              "      <td>44250</td>\n",
              "      <td>u37048</td>\n",
              "      <td>b5183</td>\n",
              "      <td>e5183</td>\n",
              "      <td>d</td>\n",
              "      <td>6</td>\n",
              "      <td>179;143</td>\n",
              "      <td>1564124620642</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1048574</th>\n",
              "      <td>1531469789721</td>\n",
              "      <td>83</td>\n",
              "      <td>q6827</td>\n",
              "      <td>d</td>\n",
              "      <td>31750</td>\n",
              "      <td>u187065</td>\n",
              "      <td>b5183</td>\n",
              "      <td>e5183</td>\n",
              "      <td>d</td>\n",
              "      <td>6</td>\n",
              "      <td>179;143</td>\n",
              "      <td>1564124620642</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1048575 rows × 12 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "             timestamp  solving_id question_id user_answer  elapsed_time  \\\n",
              "0        1552405824275           1       q5713           a         24000   \n",
              "1        1552405824275           1       q5713           a         24000   \n",
              "2        1540785188092           2       q5713           a         15000   \n",
              "3        1559943082762          17       q5713           a          8000   \n",
              "4        1535867868674         246       q5713           a         34000   \n",
              "...                ...         ...         ...         ...           ...   \n",
              "1048570  1541769524423         420       q6827           d         22750   \n",
              "1048571  1503686797917        2470       q6827           c         61000   \n",
              "1048572  1534224187825         244       q6827           d         48250   \n",
              "1048573  1518238277613         897       q6827           d         44250   \n",
              "1048574  1531469789721          83       q6827           d         31750   \n",
              "\n",
              "         user_id bundle_id explanation_id correct_answer  part     tags  \\\n",
              "0        u533092     b4245          e4245              a     5       71   \n",
              "1        u533092     b4245          e4245              a     5       71   \n",
              "2        u298664     b4245          e4245              a     5       71   \n",
              "3        u608719     b4245          e4245              a     5       71   \n",
              "4        u248874     b4245          e4245              a     5       71   \n",
              "...          ...       ...            ...            ...   ...      ...   \n",
              "1048570  u295354     b5183          e5183              d     6  179;143   \n",
              "1048571   u21819     b5183          e5183              d     6  179;143   \n",
              "1048572   u38390     b5183          e5183              d     6  179;143   \n",
              "1048573   u37048     b5183          e5183              d     6  179;143   \n",
              "1048574  u187065     b5183          e5183              d     6  179;143   \n",
              "\n",
              "           deployed_at  \n",
              "0        1568635574409  \n",
              "1        1568635574409  \n",
              "2        1568635574409  \n",
              "3        1568635574409  \n",
              "4        1568635574409  \n",
              "...                ...  \n",
              "1048570  1564124620642  \n",
              "1048571  1564124620642  \n",
              "1048572  1564124620642  \n",
              "1048573  1564124620642  \n",
              "1048574  1564124620642  \n",
              "\n",
              "[1048575 rows x 12 columns]"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "raw_data = pd.read_csv(os.path.join(EDNET_KT1_DIR, dataset_name))\n",
        "raw_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5e8f012f-d459-41c1-ae9e-bcf3ad545c05",
      "metadata": {
        "id": "5e8f012f-d459-41c1-ae9e-bcf3ad545c05",
        "outputId": "1b94c081-bab8-40ae-ed05-0cdeda6c1e60"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1048575 entries, 0 to 1048574\n",
            "Data columns (total 12 columns):\n",
            " #   Column          Non-Null Count    Dtype \n",
            "---  ------          --------------    ----- \n",
            " 0   timestamp       1048575 non-null  int64 \n",
            " 1   solving_id      1048575 non-null  int64 \n",
            " 2   question_id     1048575 non-null  object\n",
            " 3   user_answer     1048473 non-null  object\n",
            " 4   elapsed_time    1048575 non-null  int64 \n",
            " 5   user_id         1048575 non-null  object\n",
            " 6   bundle_id       1048575 non-null  object\n",
            " 7   explanation_id  1048575 non-null  object\n",
            " 8   correct_answer  1048575 non-null  object\n",
            " 9   part            1048575 non-null  int64 \n",
            " 10  tags            1048575 non-null  object\n",
            " 11  deployed_at     1048575 non-null  int64 \n",
            "dtypes: int64(5), object(7)\n",
            "memory usage: 96.0+ MB\n"
          ]
        }
      ],
      "source": [
        "raw_data.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0697865e-9963-4dc2-8e3d-9c11a1caf7c5",
      "metadata": {
        "id": "0697865e-9963-4dc2-8e3d-9c11a1caf7c5",
        "outputId": "a60ef5bb-695e-4503-da12-1b49051cbedb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The number of unique users: 14592\n",
            "The number of unique questions: 3399\n"
          ]
        }
      ],
      "source": [
        "print('The number of unique users:', len(raw_data['user_id'].unique()))\n",
        "print('The number of unique questions:', len(raw_data['question_id'].unique()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0d05dc52-5a22-4f36-921e-72c2dad04948",
      "metadata": {
        "id": "0d05dc52-5a22-4f36-921e-72c2dad04948",
        "outputId": "83a3f016-7bc2-46e4-c15c-e78bb85112d7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[<matplotlib.axes._subplots.AxesSubplot object at 0x7fb5cacf77d0>,\n",
              "        <matplotlib.axes._subplots.AxesSubplot object at 0x7fb5ca748d10>]],\n",
              "      dtype=object)"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "q_count_by_u = raw_data.groupby(['user_id'])['question_id'].count().reset_index()\n",
        "q_count_by_u.columns = ['user_id', 'q_count']\n",
        "q_count_by_u['log_q_count'] = np.log(q_count_by_u['q_count'])\n",
        "q_count_by_u.hist(bins=30)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b41fd197-d4b7-4b4a-b91f-0d8359a9965d",
      "metadata": {
        "id": "b41fd197-d4b7-4b4a-b91f-0d8359a9965d",
        "outputId": "a41f1c0e-86c9-4cc6-e660-8165bd1fbfd6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "q_count\n",
              "456       1\n",
              "701       1\n",
              "703       1\n",
              "705       1\n",
              "706       1\n",
              "       ... \n",
              "6       889\n",
              "3      1153\n",
              "30     1169\n",
              "5      1170\n",
              "4      1629\n",
              "Name: user_id, Length: 861, dtype: int64"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "q_count_by_u.groupby('q_count')['user_id'].count().sort_values()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b11d31c8-ef5d-4efc-924b-79e6eb35a98e",
      "metadata": {
        "id": "b11d31c8-ef5d-4efc-924b-79e6eb35a98e",
        "outputId": "4b98ea2e-16fe-4aee-c63d-45f69ade5ca1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The number of unique (user_id, question_id): 866603\n",
            "[ 1  2  3  4  5  6  7  8  9  0 10 13 11 12 16 15 14 17 18 19 20]\n",
            "Insight: Multiple responses per (user_id, question_id).\n"
          ]
        }
      ],
      "source": [
        "# Whether a user answers the same question more than 1 time?\n",
        "count_by_u_q = raw_data.groupby(['user_id', 'question_id'])['user_answer'].count().reset_index()\n",
        "count_by_u_q.columns = ['user_id', 'question_id', 'count']\n",
        "\n",
        "print('The number of unique (user_id, question_id):', count_by_u_q.shape[0])\n",
        "print(count_by_u_q['count'].unique())\n",
        "\n",
        "print('Insight: Multiple responses per (user_id, question_id).')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "86046508-71d7-4e22-8ad1-6e7bdf0b0b59",
      "metadata": {
        "id": "86046508-71d7-4e22-8ad1-6e7bdf0b0b59",
        "outputId": "1d4d3494-77dd-4f70-c319-ca7c26789e16"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Insight: The visualization shows enough responses per question to learn unobserved question variables.\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "raw_data.groupby('question_id')['user_id'].count().plot(kind='box')\n",
        "print('Insight: The visualization shows enough responses per question to learn unobserved question variables.')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "61eef9d4-ff9a-43e9-bb7b-453ec73fdd3a",
      "metadata": {
        "id": "61eef9d4-ff9a-43e9-bb7b-453ec73fdd3a",
        "outputId": "b549ce8b-ab8b-4fa7-96cb-bade99b35835"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "response\n",
              "False    398118\n",
              "True     650457\n",
              "Name: question_id, dtype: int64"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "raw_data['response'] = (raw_data['user_answer'] == raw_data['correct_answer'])\n",
        "raw_data.groupby('response')['question_id'].count()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "51f7d7dc-8666-4017-94c2-a64335dc6bf1",
      "metadata": {
        "id": "51f7d7dc-8666-4017-94c2-a64335dc6bf1"
      },
      "source": [
        "# Dataset Preparation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0ed6bf4f-f6e8-4482-9695-3ece1b0930fc",
      "metadata": {
        "id": "0ed6bf4f-f6e8-4482-9695-3ece1b0930fc"
      },
      "outputs": [],
      "source": [
        "class EdnetKT1(torch.utils.data.Dataset):\n",
        "    def __init__(self, ds_file='kt1_subset.csv', train=True, binarized_response=True, swap_ability_item=False, **kwargs):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.swap_ability_item = swap_ability_item\n",
        "        \n",
        "        name, _ = os.path.splitext(ds_file)\n",
        "        raw_data = pd.read_csv(os.path.join(EDNET_KT1_DIR, ds_file))\n",
        "        \n",
        "        responses = self.make_score_matrix(raw_data, name=name)\n",
        "        \n",
        "        rs = np.random.RandomState(42)\n",
        "        swapper = np.arange(responses.shape[0])\n",
        "        rs.shuffle(swapper)\n",
        "        responses = responses[swapper]\n",
        "        \n",
        "        self.binarized_response = binarized_response\n",
        "        if binarized_response:\n",
        "            responses = np.round(responses)\n",
        "            \n",
        "        num_users = responses.shape[0]\n",
        "        num_train = int(0.7 * num_users)\n",
        "        \n",
        "        if train:\n",
        "            responses = responses[:num_train]\n",
        "        else:\n",
        "            responses = responses[num_train:]\n",
        "        \n",
        "        response_mask = np.ones_like(responses)\n",
        "        response_mask[responses == MISSING_DATA] = 0\n",
        " \n",
        "        self.responses = responses\n",
        "        self.mask = response_mask\n",
        "        self.length = responses.shape[0]\n",
        "        self.num_person = responses.shape[0]\n",
        "        self.num_item = responses.shape[1]\n",
        "            \n",
        "    def make_score_matrix(self, raw_data, name):\n",
        "        cache_file = os.path.join(EDNET_KT1_DIR, f'{name}_score_matrix_swap{self.swap_ability_item}.npy'.lower())\n",
        "        if os.path.isfile(cache_file):\n",
        "            return np.load(cache_file)\n",
        "        \n",
        "        raw_data['response'] = 0\n",
        "        raw_data.loc[raw_data['user_answer'] == raw_data['correct_answer'], 'response'] = 1\n",
        "        \n",
        "        compact_score_mat = raw_data.groupby(['user_id', 'question_id'])['response'].mean().reset_index()\n",
        "        score_mat = compact_score_mat.pivot(index='user_id', columns='question_id', values='response')\n",
        "        score_mat = score_mat.fillna(MISSING_DATA)\n",
        "        score_mat = score_mat.values\n",
        "        \n",
        "        if self.swap_ability_item:\n",
        "            score_mat = np.transpose(score_mat)\n",
        "                \n",
        "        np.save(cache_file, score_mat)\n",
        "        return score_mat\n",
        "    \n",
        "    def __len__(self):\n",
        "        return self.length\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        response = self.responses[index]\n",
        "        item_id = np.arange(self.num_item)\n",
        "        item_id[response == MISSING_DATA] = MISSING_DATA\n",
        "        mask = self.mask[index]\n",
        "\n",
        "        response = torch.from_numpy(response).float().unsqueeze(1)\n",
        "        item_id = torch.from_numpy(item_id).long().unsqueeze(1)\n",
        "        mask = torch.from_numpy(mask).bool().unsqueeze(1)\n",
        "\n",
        "        return index, response, item_id, mask"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import scipy.sparse\n",
        "\n",
        "class EdnetKT1Compressed(torch.utils.data.Dataset):\n",
        "    def __init__(self, ds_file='kt1_data_0.npz', train=True, maskperc=0.3, binarized_response=True, swap_ability_item=False, **kwargs):\n",
        "        super().__init__()\n",
        "\n",
        "        self.swap_ability_item = swap_ability_item\n",
        "\n",
        "        raw_data = scipy.sparse.load_npz(os.path.join(EDNET_KT1_DIR, ds_file)).todok()\n",
        "\n",
        "        rs = np.random.RandomState(42)\n",
        "        swapper = np.arange(100000)\n",
        "        rs.shuffle(swapper)\n",
        "\n",
        "        num_users = 100000 # responses.shape[0]\n",
        "        num_train = int(0.7 * num_users)\n",
        "\n",
        "        if train:\n",
        "            index_map = swapper[:num_train]\n",
        "        else:\n",
        "            index_map = swapper[num_train:]\n",
        "\n",
        "        self.index_map = index_map\n",
        "        self.responses = raw_data\n",
        "        self.length = len(self.index_map) #raw_data.shape[0]\n",
        "        self.num_person = len(self.index_map) # raw_data.shape[0]\n",
        "        self.num_item = raw_data.shape[1]\n",
        "        self.maskperc = maskperc\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.length\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        full = self.responses[self.index_map[index], :]\n",
        "        full_size = full.getnnz()\n",
        "        unmask_size = int(full_size * (1-self.maskperc))\n",
        "        rs = np.random.RandomState(42)\n",
        "        swapper = np.arange(full_size)\n",
        "        rs.shuffle(swapper)\n",
        "        masked = swapper[unmask_size:]\n",
        "        data_indices = self.responses[self.index_map[index], :].nonzero()\n",
        "        not_keep = (data_indices[0][masked], data_indices[1][masked])\n",
        "        not_keep_indices = [x for x in zip(*not_keep)]\n",
        "        response = self.responses[self.index_map[index], :].toarray()\n",
        "        missing_mask = np.zeros(response.shape, dtype=bool)\n",
        "        missing_mask[not_keep] = 1\n",
        "        missing_data = missing_mask * response - 1\n",
        "        response = response - 1\n",
        "        response[not_keep] = -1\n",
        "        mask = np.zeros(response.shape, dtype=bool)\n",
        "        mask[data_indices] = 1\n",
        "        mask[not_keep] = 0\n",
        "        return missing_data.transpose(), response.transpose(), missing_mask.transpose(), mask.transpose()\n"
      ],
      "metadata": {
        "id": "dReHq3kJN9V-"
      },
      "id": "dReHq3kJN9V-",
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "65f1651d-f209-4d0d-84bf-bfcc8e6fd493",
      "metadata": {
        "id": "65f1651d-f209-4d0d-84bf-bfcc8e6fd493"
      },
      "outputs": [],
      "source": [
        "import copy\n",
        "\n",
        "def artificially_mask_dataset(old_dataset, perc):\n",
        "    dataset = copy.deepcopy(old_dataset)\n",
        "    assert perc >= 0 and perc <= 1\n",
        "    response = dataset.responses\n",
        "    mask = dataset.mask\n",
        "\n",
        "    if np.ndim(mask) == 2:\n",
        "        row, col = np.where(mask != 0)\n",
        "    elif np.ndim(mask) == 3:\n",
        "        row, col = np.where(mask[:, :, 0] != 0)\n",
        "    pool = np.array(list(zip(row, col)))\n",
        "    num_all = pool.shape[0]\n",
        "    num = int(perc * num_all)\n",
        "    \n",
        "    rs = np.random.RandomState(42)\n",
        "    indices = np.sort(\n",
        "        rs.choice(np.arange(num_all), size=num, replace=False),\n",
        "    )\n",
        "    label_indices = pool[indices]\n",
        "    labels = []\n",
        "    for idx in label_indices:\n",
        "        label = copy.deepcopy(response[idx[0], idx[1]])\n",
        "        labels.append(label)\n",
        "        mask[idx[0], idx[1]] = 0\n",
        "        response[idx[0], idx[1]] = -1\n",
        "    labels = np.array(labels)\n",
        "\n",
        "    dataset.response = response\n",
        "    dataset.mask = mask\n",
        "    dataset.missing_labels = labels\n",
        "    dataset.missing_indices = label_indices\n",
        "\n",
        "    return dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "58381a88-2576-42d3-aefa-2636ca683f43",
      "metadata": {
        "id": "58381a88-2576-42d3-aefa-2636ca683f43"
      },
      "source": [
        "# Implementation"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4bf78d9c-0b08-4f1e-ae1a-2ef31afd52ea",
      "metadata": {
        "id": "4bf78d9c-0b08-4f1e-ae1a-2ef31afd52ea"
      },
      "source": [
        "## Configurations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "id": "aaf16780-77f3-4d27-91bb-c83c773e728a",
      "metadata": {
        "id": "aaf16780-77f3-4d27-91bb-c83c773e728a"
      },
      "outputs": [],
      "source": [
        "### Configurations ###\n",
        "\n",
        "irt_model = '2pl'           # Available values: '1pl', '2pl' and '3pl'\n",
        "dataset = 'ednet-kt1'\n",
        "ability_dim = 8\n",
        "ability_merge = 'product'   # Available values: 'product' and 'mean'\n",
        "conditional_posterior = True\n",
        "generative_model = 'irt'    # Available values: 'irt', 'link', 'deep', 'residual'\n",
        "response_dist = 'gaussian' # Available values: 'bernoulli' and 'gaussian'\n",
        "drop_missing = False\n",
        "artificial_missing_perc = 0.3\n",
        "no_test = False\n",
        "num_person = 70000\n",
        "num_item = 13169\n",
        "# num_person = len(raw_data['user_id'].unique()) * 0.7\n",
        "# num_item = len(raw_data['question_id'].unique())\n",
        "num_posterior_samples = 10\n",
        "hidden_dim = 64\n",
        "max_num_person = None\n",
        "max_num_item = None\n",
        "swap_ability_item = False\n",
        "\n",
        "lr = 5e-3\n",
        "batch_size = 32\n",
        "epochs = 5\n",
        "max_iters = -1\n",
        "num_workers = 0\n",
        "anneal_kl = False\n",
        "beta_kl = 0.9\n",
        "\n",
        "seed = 8\n",
        "cuda = True\n",
        "gpu_device = 0\n",
        "\n",
        "torch.manual_seed(seed)\n",
        "np.random.seed(seed)\n",
        "\n",
        "num_person = None\n",
        "num_item = None\n",
        "\n",
        "if max_num_person is not None:\n",
        "    max_num_person = int(max_num_person)\n",
        "\n",
        "if max_num_item is not None:\n",
        "    max_num_item = int(max_num_item)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "47d5c7b9-03f3-4431-bc14-aa4fb08aff3e",
      "metadata": {
        "id": "47d5c7b9-03f3-4431-bc14-aa4fb08aff3e"
      },
      "source": [
        "## Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "id": "4ade9c21-5211-45f3-a04a-9d31f43d72e3",
      "metadata": {
        "id": "4ade9c21-5211-45f3-a04a-9d31f43d72e3"
      },
      "outputs": [],
      "source": [
        "class ItemInferenceNetwork(nn.Module):\n",
        "\n",
        "    def __init__(self, num_item, item_feat_dim):\n",
        "        super().__init__()\n",
        "\n",
        "        self.mu_lookup = nn.Embedding(num_item, item_feat_dim)\n",
        "        self.logvar_lookup = nn.Embedding(num_item, item_feat_dim)\n",
        "\n",
        "    def forward(self, item_index):\n",
        "        item_index = item_index.squeeze(1)\n",
        "        mu = self.mu_lookup(item_index.long())\n",
        "        logvar = self.logvar_lookup(item_index.long())\n",
        "\n",
        "        return mu, logvar\n",
        "\n",
        "def product_of_experts(mu, logvar, eps=1e-8):\n",
        "    # assume the first dimension is the number of experts\n",
        "    var = torch.exp(logvar) + eps\n",
        "    T = 1 / var  # precision of i-th Gaussian expert at point x\n",
        "    pd_mu = torch.sum(mu * T, dim=0) / torch.sum(T, dim=0)\n",
        "    pd_var = 1 / torch.sum(T, dim=0)\n",
        "    pd_logvar = torch.log(pd_var)\n",
        "\n",
        "    return pd_mu, pd_logvar    \n",
        "\n",
        "class AbilityInferenceNetwork(nn.Module):\n",
        "\n",
        "    def __init__(\n",
        "            self,\n",
        "            ability_dim,\n",
        "            response_dim,\n",
        "            hidden_dim = 64,\n",
        "            ability_merge = 'mean',\n",
        "            replace_missing_with_prior = True,\n",
        "        ):\n",
        "        super().__init__()\n",
        "\n",
        "        self.ability_dim = ability_dim\n",
        "        self.response_dim = response_dim\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.ability_merge = ability_merge\n",
        "        self.replace_missing_with_prior = replace_missing_with_prior\n",
        "\n",
        "        getattr(self, f'_create_models_{self.ability_merge}')(\n",
        "            self.response_dim, \n",
        "            self.hidden_dim,\n",
        "            self.ability_dim * 2,\n",
        "        )\n",
        "\n",
        "    def _create_models_product(self, input_dim, hidden_dim, output_dim):\n",
        "        self.mlp = nn.Sequential(\n",
        "            nn.Linear(input_dim, hidden_dim),\n",
        "            nn.ELU(inplace=True),\n",
        "            nn.Linear(hidden_dim, hidden_dim),\n",
        "            nn.ELU(inplace=True),\n",
        "            nn.Linear(hidden_dim, output_dim),\n",
        "        )\n",
        "    \n",
        "    def _create_models_mean(self, input_dim, hidden_dim, output_dim):\n",
        "        self.mlp1 = nn.Sequential(\n",
        "            nn.Linear(input_dim, hidden_dim),\n",
        "            nn.ELU(inplace=True),\n",
        "            nn.Linear(hidden_dim, hidden_dim),\n",
        "        )\n",
        "        self.mlp2 = nn.Sequential(\n",
        "            nn.Linear(hidden_dim, hidden_dim),\n",
        "            nn.ELU(inplace=True),\n",
        "            nn.Linear(hidden_dim, output_dim),\n",
        "        )\n",
        "    \n",
        "    def _forward_product(self, mlp_input, mask, num_person, num_item):\n",
        "        has_missing = bool(torch.sum(1 - mask).item()) if mask is not None else False\n",
        "\n",
        "        mu_flat, logvar_flat = torch.chunk(self.mlp(mlp_input), 2, dim=1)\n",
        "        mu_set = mu_flat.view(num_person, num_item, self.ability_dim)\n",
        "        logvar_set = logvar_flat.view(num_person, num_item, self.ability_dim)\n",
        "\n",
        "        p_mu_set = torch.zeros_like(mu_set)\n",
        "        p_logvar_set = 2. * torch.log(torch.ones_like(logvar_set) * 0.25)\n",
        "\n",
        "        if has_missing:\n",
        "            mu, logvar = [], []\n",
        "            for i in range(num_person):\n",
        "                if mask[i].sum().item() != num_item:\n",
        "                    mask_i = mask[i].bool().repeat(1, self.ability_dim)\n",
        "                    mu_set_i = mu_set[i][mask_i].view(-1, self.ability_dim)\n",
        "                    logvar_set_i = logvar_set[i][mask_i].view(-1, self.ability_dim)\n",
        "                    # replace all missing items with a prior score\n",
        "                    if self.replace_missing_with_prior:\n",
        "                        p_mu_set_i = p_mu_set[i][~mask_i].view(-1, self.ability_dim)\n",
        "                        p_logvar_set_i = p_logvar_set[i][~mask_i].view(-1, self.ability_dim)\n",
        "                        mu_set_i = torch.cat([mu_set_i, p_mu_set_i], dim=0)\n",
        "                        logvar_set_i = torch.cat([logvar_set_i, p_logvar_set_i], dim=0)\n",
        "                        assert mu_set_i.size(0) == num_item\n",
        "                        assert logvar_set_i.size(0) == num_item\n",
        "                else:\n",
        "                    mu_set_i, logvar_set_i = mu_set[i], logvar_set[i]\n",
        "                mu_i, logvar_i = product_of_experts(mu_set_i, logvar_set_i)\n",
        "                mu.append(mu_i); logvar.append(logvar_i)\n",
        "            mu, logvar = torch.stack(mu), torch.stack(logvar)\n",
        "        else:\n",
        "            mu, logvar = product_of_experts(mu_set.permute(1, 0, 2), logvar_set.permute(1, 0, 2))\n",
        "\n",
        "        return mu, logvar\n",
        "\n",
        "    def _forward_mean(self, mlp_input, mask, num_person, num_item):\n",
        "        has_missing = bool(torch.sum(1 - mask).item()) if mask is not None else False\n",
        "\n",
        "        hid = F.elu(self.mlp1(mlp_input))\n",
        "        hid = hid.view(num_person, num_item, self.hidden_dim)\n",
        "        if has_missing:\n",
        "            hid_mean = []\n",
        "            for i in range(num_person):\n",
        "                hid_i = hid[i][mask[i].repeat(1, self.hidden_dim).bool()]\n",
        "                num_i = mask[i].squeeze().sum().item()\n",
        "                hid_i = hid_i.view(num_i, self.hidden_dim)\n",
        "                hid_i_mean = hid_i.mean(0)\n",
        "                hid_mean.append(hid_i_mean)\n",
        "            hid_mean = torch.stack(hid_mean)\n",
        "        else:\n",
        "            hid_mean = hid.mean(1)\n",
        "     \n",
        "        mu, logvar = torch.chunk(self.mlp2(hid_mean), 2, dim=1)\n",
        "        \n",
        "        return mu, logvar\n",
        "\n",
        "    def forward(self, response, mask):\n",
        "        num_person, num_item, response_dim = response.size()\n",
        "        mlp_input = response.view(num_person * num_item, response_dim)\n",
        "\n",
        "        return getattr(self, f'_forward_{self.ability_merge}')(\n",
        "                mlp_input, \n",
        "                mask,\n",
        "                num_person,\n",
        "                num_item,\n",
        "            )\n",
        "\n",
        "\n",
        "class ConditionalAbilityInferenceNetwork(AbilityInferenceNetwork):\n",
        "\n",
        "    def __init__(\n",
        "            self, \n",
        "            ability_dim, \n",
        "            response_dim, \n",
        "            item_feat_dim, \n",
        "            hidden_dim = 64,\n",
        "            ability_merge = 'mean',\n",
        "            replace_missing_with_prior = True,\n",
        "        ):\n",
        "        super().__init__(\n",
        "            ability_dim,\n",
        "            response_dim,\n",
        "            hidden_dim = hidden_dim,\n",
        "            ability_merge = ability_merge,\n",
        "            replace_missing_with_prior = replace_missing_with_prior,\n",
        "        )\n",
        "        self.ability_dim = ability_dim\n",
        "        self.response_dim = response_dim\n",
        "        self.item_feat_dim = item_feat_dim\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.ability_merge = ability_merge\n",
        "        self.replace_missing_with_prior = replace_missing_with_prior\n",
        "\n",
        "        getattr(self, f'_create_models_{self.ability_merge}')(\n",
        "            self.response_dim + self.item_feat_dim, \n",
        "            self.hidden_dim,\n",
        "            self.ability_dim * 2,\n",
        "        )\n",
        "\n",
        "    def forward(self, response, mask, item_feat):\n",
        "        num_person, num_item, response_dim = response.size()\n",
        "        item_feat_dim = item_feat.size(1)\n",
        "\n",
        "        response_flat = response.view(num_person * num_item, response_dim)\n",
        "        item_feat_flat = item_feat.unsqueeze(0).repeat(num_person, 1, 1)\n",
        "        item_feat_flat = item_feat_flat.view(num_person * num_item, item_feat_dim)\n",
        "\n",
        "        mlp_input = torch.cat([response_flat, item_feat_flat], dim=1)\n",
        "\n",
        "        return getattr(self, f'_forward_{self.ability_merge}')(\n",
        "                mlp_input, \n",
        "                mask,\n",
        "                num_person,\n",
        "                num_item,\n",
        "            )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "id": "8328b946-651b-4bd2-9cf9-1ef4b5e62f5d",
      "metadata": {
        "id": "8328b946-651b-4bd2-9cf9-1ef4b5e62f5d"
      },
      "outputs": [],
      "source": [
        "def standard_normal_log_pdf(x):\n",
        "    mu = torch.zeros_like(x)\n",
        "    scale = torch.ones_like(x)\n",
        "    return torch.distributions.normal.Normal(mu, scale).log_prob(x)\n",
        "\n",
        "def normal_log_pdf(x, mu, logvar):\n",
        "    scale = torch.exp(0.5 * logvar)\n",
        "    return torch.distributions.normal.Normal(mu, scale).log_prob(x)\n",
        "\n",
        "def reparameterize_gaussian(mean, logvar):\n",
        "    std = torch.exp(0.5 * logvar)\n",
        "    eps = torch.randn_like(std)\n",
        "    return eps.mul(std).add_(mean)\n",
        "\n",
        "def masked_bernoulli_log_pdf(x, mask, probs):\n",
        "    dist = torch.distributions.bernoulli.Bernoulli(probs=probs)\n",
        "    log_prob = dist.log_prob(x)\n",
        "    return log_prob * mask.float()\n",
        "\n",
        "def masked_gaussian_log_pdf(x, mask, mu, logvar):\n",
        "    sigma = torch.exp(0.5 * logvar)\n",
        "    dist = torch.distributions.normal.Normal(mu, sigma)\n",
        "    log_prob = dist.log_prob(x)\n",
        "    return log_prob * mask.float()\n",
        "\n",
        "def kl_divergence_standard_normal_prior(z_mu, z_logvar):\n",
        "    kl_div = -0.5 * (1 + z_logvar - z_mu.pow(2) - z_logvar.exp())\n",
        "    kl_div = torch.sum(kl_div, dim=1)\n",
        "    return kl_div\n",
        "\n",
        "class LinkedIRT(nn.Module):\n",
        "\n",
        "    def __init__(self, irt_model = '1pl', hidden_dim = 64):\n",
        "        super().__init__()\n",
        "        assert irt_model in ['1pl', '2pl', '3pl']\n",
        "        self.irt_model = irt_model\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.link = nn.Sequential(\n",
        "            nn.Linear(1, self.hidden_dim),\n",
        "            nn.ELU(inplace = True),\n",
        "            nn.Linear(self.hidden_dim, self.hidden_dim),\n",
        "            nn.ELU(inplace = True),\n",
        "            nn.Linear(self.hidden_dim, 1),\n",
        "            nn.Sigmoid(),\n",
        "        )\n",
        "        self.apply(self.weights_init)\n",
        "\n",
        "    def forward(self, ability, item_feat):\n",
        "        if self.irt_model == '1pl':\n",
        "            logit = irt_model_1pl(ability, item_feat, return_logit=True)\n",
        "            response_mu = self.link(logit)\n",
        "        \n",
        "        elif self.irt_model == '2pl':\n",
        "            logit = irt_model_2pl(ability, item_feat, return_logit=True)\n",
        "            response_mu = self.link(logit)\n",
        "            \n",
        "        elif self.irt_model == '3pl':\n",
        "            logit, guess = irt_model_3pl(ability, item_feat, return_logit=True)\n",
        "            response_mu = guess + (1. - guess) * self.link(logit)\n",
        "        \n",
        "        else:\n",
        "            raise Exception(f'Unsupported irt_model {self.irt_model}.')\n",
        "\n",
        "        return response_mu\n",
        "\n",
        "    @staticmethod\n",
        "    def weights_init(m):\n",
        "        if isinstance(m, (nn.Linear, nn.Conv2d)):\n",
        "            init.xavier_normal_(m.weight.data, gain=init.calculate_gain('relu'))\n",
        "            init.constant_(m.bias.data, 0)\n",
        "        elif isinstance(m, nn.BatchNorm1d):\n",
        "            pass\n",
        "\n",
        "\n",
        "class DeepIRT(nn.Module):\n",
        "\n",
        "    def __init__(self, latent_dim, irt_model = '1pl', hidden_dim = 64):\n",
        "        super().__init__()\n",
        "        assert irt_model in ['1pl', '2pl', '3pl']\n",
        "        self.latent_dim = latent_dim\n",
        "        self.ability_dim = latent_dim\n",
        "        self.irt_model = irt_model\n",
        "        self.hidden_dim = hidden_dim\n",
        "\n",
        "        if self.irt_model == '1pl':\n",
        "            self.item_feat_dim = 1\n",
        "        elif self.irt_model == '2pl':\n",
        "            self.item_feat_dim = self.latent_dim + 1\n",
        "        elif self.irt_model == '3pl':\n",
        "            self.item_feat_dim = self.latent_dim + 2\n",
        "\n",
        "        self.mlp_item_feat = nn.Sequential(\n",
        "            nn.Linear(self.item_feat_dim, self.hidden_dim),\n",
        "            nn.ELU(inplace = True),\n",
        "            nn.Linear(self.hidden_dim, self.hidden_dim),\n",
        "            nn.ELU(inplace = True),\n",
        "            nn.Linear(self.hidden_dim, self.hidden_dim),\n",
        "        )\n",
        "        self.mlp_ability = nn.Sequential(\n",
        "            nn.Linear(self.ability_dim, self.hidden_dim),\n",
        "            nn.ELU(inplace = True),\n",
        "            nn.Linear(self.hidden_dim, self.hidden_dim),\n",
        "            nn.ELU(inplace = True),\n",
        "            nn.Linear(self.hidden_dim, self.hidden_dim),\n",
        "        )\n",
        "        self.mlp_concat = nn.Sequential(\n",
        "            nn.Linear(2 * self.hidden_dim, self.hidden_dim),\n",
        "            nn.ELU(inplace=True),\n",
        "            nn.Linear(self.hidden_dim, self.hidden_dim),\n",
        "            nn.ELU(inplace=True),\n",
        "            nn.Linear(self.hidden_dim, 1),\n",
        "        )\n",
        "        self.apply(self.weights_init)\n",
        "    \n",
        "    def forward(self, ability, item_feat):\n",
        "        num_person, num_item = ability.size(0), item_feat.size(0)\n",
        "\n",
        "        hid_ability = self.mlp_ability(ability)\n",
        "        hid_item_feat = self.mlp_item_feat(item_feat)\n",
        "        \n",
        "        hid_ability = hid_ability.unsqueeze(1).repeat(1, num_item, 1)\n",
        "        hid_item_feat = hid_item_feat.unsqueeze(0).repeat(num_person, 1, 1)\n",
        "\n",
        "        hid = torch.cat([hid_item_feat, hid_ability], dim=2)\n",
        "        hid = self.mlp_concat(hid)\n",
        "        response_mu = torch.sigmoid(hid)\n",
        "        return response_mu\n",
        "\n",
        "    @staticmethod\n",
        "    def weights_init(m):\n",
        "        if isinstance(m, (nn.Linear, nn.Conv2d)):\n",
        "            init.xavier_normal_(m.weight.data, gain=init.calculate_gain('relu'))\n",
        "            init.constant_(m.bias.data, 0)\n",
        "        elif isinstance(m, nn.BatchNorm1d):\n",
        "            pass\n",
        "\n",
        "\n",
        "class ResidualIRT(DeepIRT):\n",
        "    \n",
        "    def __init__(self, latent_dim, irt_model = '1pl', hidden_dim = 64):\n",
        "        super().__init__(\n",
        "            latent_dim, \n",
        "            irt_model = irt_model, \n",
        "            hidden_dim = hidden_dim,\n",
        "        )\n",
        "        self.apply(self.zero_init)\n",
        "\n",
        "    def residual_forward(self, ability, item_feat):\n",
        "        num_person, num_item = ability.size(0), item_feat.size(0)\n",
        "        hid_ability = self.mlp_ability(ability)\n",
        "        hid_item_feat = self.mlp_item_feat(item_feat)\n",
        "        hid_ability = hid_ability.unsqueeze(1).repeat(1, num_item, 1)\n",
        "        hid_item_feat = hid_item_feat.unsqueeze(0).repeat(num_person, 1, 1)\n",
        "        hid = torch.cat([hid_item_feat, hid_ability], dim=2)\n",
        "        return self.mlp_concat(hid)\n",
        "\n",
        "    def forward(self, ability, item_feat):\n",
        "        res_logit = self.residual_forward(ability, item_feat)\n",
        "\n",
        "        if self.irt_model == '1pl':\n",
        "            irt_logit = irt_model_1pl(ability, item_feat, return_logit=True)\n",
        "            return torch.sigmoid(res_logit + irt_logit)\n",
        "\n",
        "        elif self.irt_model == '2pl':\n",
        "            irt_logit = irt_model_2pl(ability, item_feat, return_logit=True)\n",
        "            return torch.sigmoid(res_logit + irt_logit)\n",
        "\n",
        "        elif self.irt_model == '3pl':\n",
        "            irt_logit, guess = irt_model_3pl(ability, item_feat, return_logit=True)\n",
        "            return guess + (1. - guess) * torch.sigmoid(res_logit + irt_logit)\n",
        "        \n",
        "        else:\n",
        "            raise Exception(f'Unsupported irt_model {self.irt_model}.')\n",
        "\n",
        "    @staticmethod\n",
        "    def zero_init(m):\n",
        "        if isinstance(m, (nn.Linear, nn.Conv2d)):\n",
        "            init.xavier_normal_(m.weight.data, gain=init.calculate_gain('relu'))\n",
        "            init.constant(m.bias.data, 0)\n",
        "        elif isinstance(m, nn.BatchNorm1d):\n",
        "            pass\n",
        "\n",
        "def irt_model_1pl(ability, item_feat, return_logit=False):\n",
        "    difficulty = torch.sum(item_feat, dim=1, keepdim=True)\n",
        "    logit = (torch.sum(ability, dim=1, keepdim=True) + difficulty.T).unsqueeze(2)\n",
        "    if return_logit:\n",
        "        return logit\n",
        "    else:\n",
        "        response_mu = torch.sigmoid(logit)\n",
        "        return response_mu\n",
        "\n",
        "\n",
        "def irt_model_2pl(ability, item_feat, return_logit=False):\n",
        "    ability_dim = ability.size(1)\n",
        "    discrimination = item_feat[:, :ability_dim]\n",
        "    difficulty = item_feat[:, ability_dim:]\n",
        "    logit = (torch.mm(ability, -discrimination.T) + difficulty.T).unsqueeze(2)\n",
        "    \n",
        "    if return_logit:\n",
        "        return logit\n",
        "    else:\n",
        "        response_mu = torch.sigmoid(logit)\n",
        "        return response_mu\n",
        "\n",
        "\n",
        "def irt_model_3pl(ability, item_feat, return_logit=False):\n",
        "    ability_dim = ability.size(1)\n",
        "    discrimination = item_feat[:, :ability_dim]\n",
        "    difficulty = item_feat[:, ability_dim:ability_dim+1]\n",
        "    guess_logit = item_feat[:, ability_dim+1:ability_dim+2]\n",
        "    guess = torch.sigmoid(guess_logit)\n",
        "    logit = (torch.mm(ability, -discrimination.T) + difficulty.T).unsqueeze(2)\n",
        "    \n",
        "    if return_logit:\n",
        "        return logit, guess\n",
        "    else:\n",
        "        guess = guess.unsqueeze(0)  \n",
        "        response_mu = guess + (1. - guess) * torch.sigmoid(logit)\n",
        "        return response_mu\n",
        "\n",
        "class VIBO_1PL(nn.Module):\n",
        "    \n",
        "    def __init__(\n",
        "            self, \n",
        "            latent_dim, \n",
        "            num_item, \n",
        "            hidden_dim = 64,\n",
        "            ability_merge = 'mean',\n",
        "            conditional_posterior = False,\n",
        "            generative_model = 'irt',\n",
        "            response_dist = 'bernoulli',\n",
        "            replace_missing_with_prior = True,\n",
        "        ):\n",
        "        super().__init__()\n",
        "\n",
        "        assert ability_merge in ['mean', 'product']\n",
        "        assert generative_model in ['irt', 'link', 'deep', 'residual']\n",
        "        assert response_dist in ['bernoulli', 'gaussian']\n",
        "\n",
        "        self.latent_dim            = latent_dim\n",
        "        self.ability_dim           = latent_dim\n",
        "        self.response_dim          = 1\n",
        "        self.hidden_dim            = hidden_dim\n",
        "        self.num_item              = num_item\n",
        "        self.ability_merge         = ability_merge\n",
        "        self.conditional_posterior = conditional_posterior\n",
        "        self.generative_model      = generative_model\n",
        "        self.response_dist         = response_dist\n",
        "        self.replace_missing_with_prior = replace_missing_with_prior\n",
        "\n",
        "        self._set_item_feat_dim()\n",
        "        self._set_irt_num()\n",
        "\n",
        "        if self.conditional_posterior:\n",
        "            self.ability_encoder = ConditionalAbilityInferenceNetwork(\n",
        "                self.ability_dim, \n",
        "                self.response_dim, \n",
        "                self.item_feat_dim, \n",
        "                self.hidden_dim, \n",
        "                ability_merge = self.ability_merge,\n",
        "                replace_missing_with_prior = self.replace_missing_with_prior,\n",
        "            )\n",
        "        else:\n",
        "            self.ability_encoder = AbilityInferenceNetwork(\n",
        "                self.ability_dim, \n",
        "                self.response_dim, \n",
        "                self.hidden_dim, \n",
        "                ability_merge = self.ability_merge,\n",
        "                replace_missing_with_prior = self.replace_missing_with_prior,\n",
        "            )\n",
        "\n",
        "        self.item_encoder = ItemInferenceNetwork(self.num_item, self.item_feat_dim) \n",
        "\n",
        "        if self.generative_model == 'link':\n",
        "            self.decoder = LinkedIRT(\n",
        "                irt_model = f'{self.irt_num}pl',\n",
        "                hidden_dim = self.hidden_dim,\n",
        "            )\n",
        "        elif self.generative_model == 'deep':\n",
        "            self.decoder = DeepIRT(\n",
        "                self.ability_dim,\n",
        "                irt_model = f'{self.irt_num}pl',\n",
        "                hidden_dim = self.hidden_dim,\n",
        "            )\n",
        "        elif self.generative_model == 'residual':\n",
        "            self.decoder = ResidualIRT(\n",
        "                self.ability_dim,\n",
        "                irt_model = f'{self.irt_num}pl',\n",
        "                hidden_dim = self.hidden_dim,\n",
        "            )\n",
        "\n",
        "        self.apply(self.weights_init)\n",
        "\n",
        "    def _set_item_feat_dim(self):\n",
        "        self.item_feat_dim = self.latent_dim\n",
        "\n",
        "    def _set_irt_num(self):\n",
        "        self.irt_num = 1\n",
        "\n",
        "    def forward(self, response, mask):\n",
        "        ability, ability_mu, ability_logvar, \\\n",
        "        item_feat, item_feat_mu, item_feat_logvar \\\n",
        "            = self.encode(response, mask)\n",
        "\n",
        "        response_mu = self.decode(ability, item_feat)\n",
        "        return response, mask, response_mu, \\\n",
        "            ability, ability_mu, ability_logvar, \\\n",
        "            item_feat, item_feat_mu, item_feat_logvar\n",
        "\n",
        "    def encode(self, response, mask):\n",
        "        device = response.device\n",
        "\n",
        "        item_domain = torch.arange(self.num_item).unsqueeze(1).to(device)\n",
        "        item_feat_mu, item_feat_logvar = self.item_encoder(item_domain)\n",
        "        item_feat = reparameterize_gaussian(item_feat_mu, item_feat_logvar)\n",
        "\n",
        "        if self.conditional_posterior:\n",
        "            ability_mu, ability_logvar = self.ability_encoder(response, mask, item_feat) \n",
        "        else:\n",
        "            ability_mu, ability_logvar = self.ability_encoder(response, mask)\n",
        "\n",
        "        ability = reparameterize_gaussian(ability_mu, ability_logvar)\n",
        "\n",
        "        return ability, ability_mu, ability_logvar, \\\n",
        "                item_feat, item_feat_mu, item_feat_logvar\n",
        "\n",
        "    def decode(self, ability, item_feat):\n",
        "        if self.generative_model == 'irt':\n",
        "            response_mu = irt_model_1pl(ability, item_feat)\n",
        "            return response_mu\n",
        "        else:\n",
        "            return self.decoder(ability, item_feat)\n",
        "\n",
        "    def elbo(\n",
        "            self, \n",
        "            response,\n",
        "            mask, \n",
        "            response_mu, \n",
        "            ability, \n",
        "            ability_mu, \n",
        "            ability_logvar,\n",
        "            item_feat, \n",
        "            item_feat_mu, \n",
        "            item_feat_logvar, \n",
        "            annealing_factor = 1,\n",
        "            use_kl_divergence = True,\n",
        "            ability_k = None,\n",
        "            item_feat_k = None,\n",
        "            ability_logabsdetjac = None,\n",
        "            item_logabsdetjac = None,\n",
        "        ):\n",
        "        if self.response_dist == 'bernoulli':\n",
        "            log_p_r_j_given_d_u = masked_bernoulli_log_pdf(response, mask, response_mu).sum()\n",
        "        elif self.response_dist == 'gaussian':\n",
        "            response_logvar = 2. * torch.log(torch.ones_like(response_mu) * 0.1)\n",
        "            log_p_r_j_given_d_u = masked_gaussian_log_pdf(response, mask, response_mu, response_logvar).sum()\n",
        "        else:\n",
        "            raise Exception(f'response_dist {self.response_dist} not supported.')\n",
        "        \n",
        "        if use_kl_divergence:\n",
        "            kl_q_u_p_u = kl_divergence_standard_normal_prior(ability_mu, ability_logvar).sum()\n",
        "            kl_q_d_p_d = kl_divergence_standard_normal_prior(item_feat_mu, item_feat_logvar).sum()\n",
        "            elbo = log_p_r_j_given_d_u - annealing_factor * kl_q_u_p_u - annealing_factor * kl_q_d_p_d\n",
        "\n",
        "        else:\n",
        "            log_p_u = standard_normal_log_pdf(ability).sum()\n",
        "            log_p_d = standard_normal_log_pdf(item_feat).sum()\n",
        "            log_q_u = normal_log_pdf(ability, ability_mu, ability_logvar).sum()\n",
        "            log_q_d = normal_log_pdf(item_feat, item_feat_mu, item_feat_logvar).sum()\n",
        "\n",
        "            model_log_prob_sum = log_p_r_j_given_d_u + log_p_u + log_p_d\n",
        "            guide_log_prob_sum = log_q_u + log_q_d\n",
        "\n",
        "            elbo = model_log_prob_sum - guide_log_prob_sum\n",
        "\n",
        "        return -elbo\n",
        "\n",
        "    def log_marginal(self, response, mask, num_samples=100):\n",
        "        with torch.no_grad():\n",
        "            log_weight = []\n",
        "            for _ in range(num_samples):\n",
        "                \n",
        "                (\n",
        "                    response, \n",
        "                    mask, \n",
        "                    response_mu, \n",
        "                    ability, \n",
        "                    ability_mu, \n",
        "                    ability_logvar,\n",
        "                    item_feat, \n",
        "                    item_feat_mu, \n",
        "                    item_feat_logvar, \n",
        "                ) = self.forward(response, mask)\n",
        "                ability_k = None\n",
        "                item_feat_k = None\n",
        "                ability_logabsdetjac = None\n",
        "                item_feat_logabsdetjac = None\n",
        "\n",
        "                log_w = -self.elbo(\n",
        "                    response,\n",
        "                    mask,\n",
        "                    response_mu,\n",
        "                    ability,\n",
        "                    ability_mu,\n",
        "                    ability_logvar,\n",
        "                    item_feat,\n",
        "                    item_feat_mu,\n",
        "                    item_feat_logvar,\n",
        "                    annealing_factor = 1,\n",
        "                    use_kl_divergence = False,\n",
        "                    ability_k = ability_k,\n",
        "                    item_feat_k = item_feat_k,\n",
        "                    ability_logabsdetjac = ability_logabsdetjac,\n",
        "                    item_logabsdetjac = item_feat_logabsdetjac,\n",
        "                )\n",
        "                log_weight.append(log_w)\n",
        "\n",
        "            log_weight = torch.stack(log_weight)\n",
        "            logp = torch.logsumexp(log_weight, 0) - math.log(num_samples)\n",
        "\n",
        "        return logp\n",
        "\n",
        "    @staticmethod\n",
        "    def weights_init(m):\n",
        "        if isinstance(m, (nn.Linear, nn.Conv2d)):\n",
        "            init.xavier_normal_(m.weight.data, gain=init.calculate_gain('relu'))\n",
        "            init.constant_(m.bias.data, 0)\n",
        "        elif isinstance(m, nn.BatchNorm1d):\n",
        "            pass\n",
        "\n",
        "\n",
        "class VIBO_2PL(VIBO_1PL):\n",
        "\n",
        "    def _set_item_feat_dim(self):\n",
        "        self.item_feat_dim = self.latent_dim + 1\n",
        "\n",
        "    def _set_irt_num(self):\n",
        "        self.irt_num = 2\n",
        "\n",
        "    def decode(self, ability, item_feat):\n",
        "        if self.generative_model == 'irt':\n",
        "            return irt_model_2pl(ability, item_feat)\n",
        "        else:\n",
        "            return self.decoder(ability, item_feat)\n",
        "\n",
        "\n",
        "class VIBO_3PL(VIBO_2PL):\n",
        "\n",
        "    def _set_item_feat_dim(self):\n",
        "        self.item_feat_dim = self.latent_dim + 2\n",
        "\n",
        "    def _set_irt_num(self):\n",
        "        self.irt_num = 3\n",
        "\n",
        "    def decode(self, ability, item_feat):        \n",
        "        if self.generative_model == 'irt':\n",
        "            return irt_model_3pl(ability, item_feat)\n",
        "        else:\n",
        "            return self.decoder(ability, item_feat)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "id": "66f84134-4735-495e-a848-60fefc117ee3",
      "metadata": {
        "id": "66f84134-4735-495e-a848-60fefc117ee3"
      },
      "outputs": [],
      "source": [
        "out_file = 'VIBO_{}_{}_{}_{}_{}maskperc_{}ability_{}_{}_seed{}_conditional_posterior{}_batch_size{}_epochs{}_lr{}_anneal_kl{}_beta_kl{}'.format(\n",
        "    irt_model, \n",
        "    dataset,\n",
        "    response_dist,\n",
        "    generative_model,\n",
        "    artificial_missing_perc,\n",
        "    ability_dim, \n",
        "    ability_merge,\n",
        "    'conditional_q' if conditional_posterior else 'unconditional_q',\n",
        "    seed,\n",
        "    conditional_posterior,\n",
        "    batch_size,\n",
        "    epochs,\n",
        "    lr,\n",
        "    anneal_kl,\n",
        "    beta_kl,\n",
        ")\n",
        "out_dir = os.path.join(OUT_DIR, out_file)\n",
        "if not os.path.isdir(out_dir):\n",
        "    os.makedirs(out_dir)\n",
        "    \n",
        "device = torch.device('cuda' if cuda else 'cpu')\n",
        "if cuda: torch.cuda.set_device(gpu_device)\n",
        "\n",
        "train_dataset = EdnetKT1Compressed(train=True, maskperc=0.0, binarized_response=False, swap_ability_item=swap_ability_item)\n",
        "test_dataset  = EdnetKT1Compressed(train=False, maskperc=artificial_missing_perc, binarized_response=False, swap_ability_item=swap_ability_item)\n",
        "\n",
        "#if artificial_missing_perc > 0:\n",
        "#    train_dataset = artificially_mask_dataset(\n",
        "#        train_dataset,\n",
        "#        artificial_missing_perc,\n",
        "#    )\n",
        "\n",
        "num_person = train_dataset.num_person\n",
        "num_item = train_dataset.num_item\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "    train_dataset, \n",
        "    batch_size = batch_size, \n",
        "    shuffle = True,\n",
        "    num_workers = num_workers,\n",
        ")\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "    test_dataset, \n",
        "    batch_size = batch_size, \n",
        "    shuffle = False,\n",
        "    num_workers = num_workers,\n",
        ")\n",
        "N_mini_batches = len(train_loader)\n",
        "if max_iters != -1:\n",
        "    epochs = int(math.ceil(max_iters / float(len(train_loader))))\n",
        "    print(f'Found MAX_ITERS={max_iters}, setting EPOCHS={epochs}')\n",
        "\n",
        "if irt_model == '1pl':\n",
        "    model_class = VIBO_1PL\n",
        "elif irt_model == '2pl':\n",
        "    model_class = VIBO_2PL\n",
        "elif irt_model == '3pl':\n",
        "    model_class = VIBO_3PL\n",
        "else:\n",
        "    raise Exception(f'model {irt_model} not recognized')\n",
        "\n",
        "model = model_class(\n",
        "    ability_dim,\n",
        "    num_item,\n",
        "    hidden_dim = hidden_dim,\n",
        "    ability_merge = ability_merge,\n",
        "    conditional_posterior = conditional_posterior,\n",
        "    generative_model = generative_model,\n",
        "    response_dist = response_dist,\n",
        "    replace_missing_with_prior = not drop_missing,\n",
        ").to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e50b178f-d714-4639-978e-a6093f9ea392",
      "metadata": {
        "id": "e50b178f-d714-4639-978e-a6093f9ea392"
      },
      "source": [
        "## Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "id": "e2e6c475-562c-4f14-a98d-c6e7ac710d35",
      "metadata": {
        "id": "e2e6c475-562c-4f14-a98d-c6e7ac710d35"
      },
      "outputs": [],
      "source": [
        "class AverageMeter(object):\n",
        "    \"\"\"Computes and stores the average and current value\"\"\"\n",
        "    def __init__(self):\n",
        "        self.reset()\n",
        "\n",
        "    def reset(self):\n",
        "        self.val = 0\n",
        "        self.avg = 0\n",
        "        self.sum = 0\n",
        "        self.count = 0\n",
        "\n",
        "    def update(self, val, n=1):\n",
        "        self.val = val\n",
        "        self.sum += val * n\n",
        "        self.count += n\n",
        "        self.avg = self.sum / self.count\n",
        "\n",
        "\n",
        "def save_checkpoint(state, is_best, folder='./', filename='checkpoint.pth.tar'):\n",
        "    if not os.path.isdir(folder):\n",
        "        os.makedirs(folder)\n",
        "    torch.save(state, os.path.join(folder, filename))\n",
        "    if is_best:\n",
        "        shutil.copyfile(os.path.join(folder, filename),\n",
        "                        os.path.join(folder, 'model_best.pth.tar'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "id": "14cede0f-bef2-4cf1-a3b1-8a8e2772f347",
      "metadata": {
        "id": "14cede0f-bef2-4cf1-a3b1-8a8e2772f347"
      },
      "outputs": [],
      "source": [
        "def get_annealing_factor(epoch, which_mini_batch):\n",
        "    if anneal_kl:\n",
        "        annealing_factor = \\\n",
        "            (float(which_mini_batch + epoch * N_mini_batches + 1) /\n",
        "             float(epochs // 2 * N_mini_batches))\n",
        "    else:\n",
        "        annealing_factor = beta_kl \n",
        "    return annealing_factor\n",
        "\n",
        "def train(epoch):\n",
        "    model.train()\n",
        "    train_loss = AverageMeter()\n",
        "    pbar = tqdm(total=len(train_loader))\n",
        "\n",
        "    for batch_idx, (_, response, _, mask) in enumerate(train_loader):\n",
        "        mb = response.size(0)\n",
        "        response = response.to(device)\n",
        "        mask = mask.long().to(device)\n",
        "        annealing_factor = get_annealing_factor(epoch, batch_idx)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        outputs = model(response, mask)\n",
        "        loss = model.elbo(*outputs, annealing_factor=annealing_factor, use_kl_divergence=True)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss.update(loss.item(), mb)\n",
        "\n",
        "        pbar.update()\n",
        "        pbar.set_postfix({'Loss': train_loss.avg})\n",
        "\n",
        "    pbar.close()\n",
        "    print('====> Train Epoch: {} Loss: {:.4f}'.format(epoch, train_loss.avg))\n",
        "\n",
        "    return train_loss.avg\n",
        "\n",
        "def test(epoch):\n",
        "    model.eval()\n",
        "    test_loss = AverageMeter()\n",
        "    pbar = tqdm(total=len(test_loader))\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for _, response, _, mask in test_loader:\n",
        "            mb = response.size(0)\n",
        "            response = response.to(device)\n",
        "            mask = mask.long().to(device)\n",
        "\n",
        "            \n",
        "            outputs = model(response, mask)\n",
        "            loss = model.elbo(*outputs)\n",
        "            test_loss.update(loss.item(), mb)\n",
        "\n",
        "            pbar.update()\n",
        "            pbar.set_postfix({'Loss': test_loss.avg})\n",
        "\n",
        "    pbar.close()\n",
        "    print('====> Test Epoch: {} Loss: {:.4f}'.format(epoch, test_loss.avg))\n",
        "\n",
        "    return test_loss.avg\n",
        "\n",
        "def get_log_marginal_density(loader):\n",
        "    model.eval()\n",
        "    meter = AverageMeter()\n",
        "    pbar = tqdm(total=len(loader))\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for _, response, _, mask in loader:\n",
        "            mb = response.size(0)\n",
        "            response = response.to(device)\n",
        "            mask = mask.long().to(device)\n",
        "\n",
        "            marginal = model.log_marginal(\n",
        "                response, \n",
        "                mask, \n",
        "                num_samples=num_posterior_samples,\n",
        "            )\n",
        "            marginal = torch.mean(marginal)\n",
        "            meter.update(marginal.item(), mb)\n",
        "\n",
        "            pbar.update()\n",
        "            pbar.set_postfix({'Marginal': meter.avg})\n",
        "\n",
        "    pbar.close()\n",
        "    print('====> Marginal: {:.4f}'.format(meter.avg))\n",
        "\n",
        "    return meter.avg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "id": "a59d4c7a-4146-46d6-87b8-8a6d2c3da3f3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a59d4c7a-4146-46d6-87b8-8a6d2c3da3f3",
        "outputId": "05f259e8-f8eb-487d-ae2d-58349cb8cb55"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 90%|█████████ | 1980/2188 [21:38<02:19,  1.49it/s, Loss=4.51e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 91%|█████████ | 1981/2188 [21:39<02:44,  1.26it/s, Loss=4.51e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 91%|█████████ | 1981/2188 [21:39<02:44,  1.26it/s, Loss=4.52e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 91%|█████████ | 1982/2188 [21:40<02:49,  1.21it/s, Loss=4.52e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 91%|█████████ | 1982/2188 [21:40<02:49,  1.21it/s, Loss=4.52e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 91%|█████████ | 1983/2188 [21:41<02:52,  1.19it/s, Loss=4.52e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 91%|█████████ | 1983/2188 [21:41<02:52,  1.19it/s, Loss=4.52e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 91%|█████████ | 1984/2188 [21:41<02:34,  1.32it/s, Loss=4.52e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 91%|█████████ | 1984/2188 [21:41<02:34,  1.32it/s, Loss=4.52e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 91%|█████████ | 1985/2188 [21:42<02:21,  1.43it/s, Loss=4.52e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 91%|█████████ | 1985/2188 [21:42<02:21,  1.43it/s, Loss=4.51e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 91%|█████████ | 1986/2188 [21:42<02:14,  1.51it/s, Loss=4.51e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 91%|█████████ | 1986/2188 [21:42<02:14,  1.51it/s, Loss=4.51e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 91%|█████████ | 1987/2188 [21:43<02:06,  1.59it/s, Loss=4.51e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 91%|█████████ | 1987/2188 [21:43<02:06,  1.59it/s, Loss=4.51e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 91%|█████████ | 1988/2188 [21:43<02:02,  1.63it/s, Loss=4.51e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 91%|█████████ | 1988/2188 [21:43<02:02,  1.63it/s, Loss=4.51e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 91%|█████████ | 1989/2188 [21:44<01:58,  1.68it/s, Loss=4.51e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 91%|█████████ | 1989/2188 [21:44<01:58,  1.68it/s, Loss=4.51e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 91%|█████████ | 1990/2188 [21:45<01:56,  1.70it/s, Loss=4.51e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 91%|█████████ | 1990/2188 [21:45<01:56,  1.70it/s, Loss=4.51e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 91%|█████████ | 1991/2188 [21:45<01:53,  1.74it/s, Loss=4.51e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 91%|█████████ | 1991/2188 [21:45<01:53,  1.74it/s, Loss=4.51e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 91%|█████████ | 1992/2188 [21:46<01:54,  1.71it/s, Loss=4.51e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 91%|█████████ | 1992/2188 [21:46<01:54,  1.71it/s, Loss=4.51e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 91%|█████████ | 1993/2188 [21:46<01:51,  1.74it/s, Loss=4.51e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 91%|█████████ | 1993/2188 [21:46<01:51,  1.74it/s, Loss=4.51e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 91%|█████████ | 1994/2188 [21:47<01:52,  1.73it/s, Loss=4.51e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 91%|█████████ | 1994/2188 [21:47<01:52,  1.73it/s, Loss=4.51e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 91%|█████████ | 1995/2188 [21:47<01:53,  1.70it/s, Loss=4.51e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 91%|█████████ | 1995/2188 [21:47<01:53,  1.70it/s, Loss=4.51e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 91%|█████████ | 1996/2188 [21:48<01:53,  1.69it/s, Loss=4.51e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 91%|█████████ | 1996/2188 [21:48<01:53,  1.69it/s, Loss=4.51e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 91%|█████████▏| 1997/2188 [21:49<01:52,  1.69it/s, Loss=4.51e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 91%|█████████▏| 1997/2188 [21:49<01:52,  1.69it/s, Loss=4.51e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 91%|█████████▏| 1998/2188 [21:49<01:53,  1.68it/s, Loss=4.51e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 91%|█████████▏| 1998/2188 [21:49<01:53,  1.68it/s, Loss=4.51e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 91%|█████████▏| 1999/2188 [21:50<01:51,  1.70it/s, Loss=4.51e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 91%|█████████▏| 1999/2188 [21:50<01:51,  1.70it/s, Loss=4.51e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 91%|█████████▏| 2000/2188 [21:50<01:49,  1.71it/s, Loss=4.51e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 91%|█████████▏| 2000/2188 [21:50<01:49,  1.71it/s, Loss=4.51e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 91%|█████████▏| 2001/2188 [21:51<02:03,  1.52it/s, Loss=4.51e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 91%|█████████▏| 2001/2188 [21:51<02:03,  1.52it/s, Loss=4.51e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 91%|█████████▏| 2002/2188 [21:52<02:14,  1.38it/s, Loss=4.51e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 91%|█████████▏| 2002/2188 [21:52<02:14,  1.38it/s, Loss=4.5e+4] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 92%|█████████▏| 2003/2188 [21:53<02:29,  1.24it/s, Loss=4.5e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 92%|█████████▏| 2003/2188 [21:53<02:29,  1.24it/s, Loss=4.51e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 92%|█████████▏| 2004/2188 [21:54<02:31,  1.21it/s, Loss=4.51e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 92%|█████████▏| 2004/2188 [21:54<02:31,  1.21it/s, Loss=4.51e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 92%|█████████▏| 2005/2188 [21:55<02:16,  1.34it/s, Loss=4.51e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 92%|█████████▏| 2005/2188 [21:55<02:16,  1.34it/s, Loss=4.5e+4] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 92%|█████████▏| 2006/2188 [21:55<02:07,  1.43it/s, Loss=4.5e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 92%|█████████▏| 2006/2188 [21:55<02:07,  1.43it/s, Loss=4.5e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 92%|█████████▏| 2007/2188 [21:56<02:01,  1.49it/s, Loss=4.5e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 92%|█████████▏| 2007/2188 [21:56<02:01,  1.49it/s, Loss=4.5e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 92%|█████████▏| 2008/2188 [21:56<01:55,  1.56it/s, Loss=4.5e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 92%|█████████▏| 2008/2188 [21:56<01:55,  1.56it/s, Loss=4.5e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 92%|█████████▏| 2009/2188 [21:57<01:53,  1.58it/s, Loss=4.5e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 92%|█████████▏| 2009/2188 [21:57<01:53,  1.58it/s, Loss=4.51e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 92%|█████████▏| 2010/2188 [21:58<01:49,  1.63it/s, Loss=4.51e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 92%|█████████▏| 2010/2188 [21:58<01:49,  1.63it/s, Loss=4.5e+4] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 92%|█████████▏| 2011/2188 [21:58<01:44,  1.69it/s, Loss=4.5e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 92%|█████████▏| 2011/2188 [21:58<01:44,  1.69it/s, Loss=4.5e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 92%|█████████▏| 2012/2188 [21:59<01:42,  1.71it/s, Loss=4.5e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 92%|█████████▏| 2012/2188 [21:59<01:42,  1.71it/s, Loss=4.5e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 92%|█████████▏| 2013/2188 [21:59<01:41,  1.72it/s, Loss=4.5e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 92%|█████████▏| 2013/2188 [21:59<01:41,  1.72it/s, Loss=4.5e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 92%|█████████▏| 2014/2188 [22:00<01:40,  1.73it/s, Loss=4.5e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 92%|█████████▏| 2014/2188 [22:00<01:40,  1.73it/s, Loss=4.5e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 92%|█████████▏| 2015/2188 [22:00<01:38,  1.75it/s, Loss=4.5e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 92%|█████████▏| 2015/2188 [22:00<01:38,  1.75it/s, Loss=4.5e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 92%|█████████▏| 2016/2188 [22:01<01:37,  1.77it/s, Loss=4.5e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 92%|█████████▏| 2016/2188 [22:01<01:37,  1.77it/s, Loss=4.5e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 92%|█████████▏| 2017/2188 [22:01<01:36,  1.78it/s, Loss=4.5e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 92%|█████████▏| 2017/2188 [22:01<01:36,  1.78it/s, Loss=4.5e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 92%|█████████▏| 2018/2188 [22:02<01:38,  1.73it/s, Loss=4.5e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 92%|█████████▏| 2018/2188 [22:02<01:38,  1.73it/s, Loss=4.5e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 92%|█████████▏| 2019/2188 [22:03<01:36,  1.75it/s, Loss=4.5e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 92%|█████████▏| 2019/2188 [22:03<01:36,  1.75it/s, Loss=4.5e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 92%|█████████▏| 2020/2188 [22:03<01:36,  1.75it/s, Loss=4.5e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 92%|█████████▏| 2020/2188 [22:03<01:36,  1.75it/s, Loss=4.5e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 92%|█████████▏| 2021/2188 [22:04<01:35,  1.74it/s, Loss=4.5e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 92%|█████████▏| 2021/2188 [22:04<01:35,  1.74it/s, Loss=4.49e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 92%|█████████▏| 2022/2188 [22:05<01:46,  1.56it/s, Loss=4.49e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 92%|█████████▏| 2022/2188 [22:05<01:46,  1.56it/s, Loss=4.49e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 92%|█████████▏| 2023/2188 [22:05<01:54,  1.44it/s, Loss=4.49e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 92%|█████████▏| 2023/2188 [22:05<01:54,  1.44it/s, Loss=4.49e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 93%|█████████▎| 2024/2188 [22:06<02:09,  1.27it/s, Loss=4.49e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 93%|█████████▎| 2024/2188 [22:06<02:09,  1.27it/s, Loss=4.49e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 93%|█████████▎| 2025/2188 [22:07<02:12,  1.23it/s, Loss=4.49e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 93%|█████████▎| 2025/2188 [22:07<02:12,  1.23it/s, Loss=4.49e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 93%|█████████▎| 2026/2188 [22:08<02:03,  1.31it/s, Loss=4.49e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 93%|█████████▎| 2026/2188 [22:08<02:03,  1.31it/s, Loss=4.49e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 93%|█████████▎| 2027/2188 [22:08<01:53,  1.41it/s, Loss=4.49e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 93%|█████████▎| 2027/2188 [22:08<01:53,  1.41it/s, Loss=4.49e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 93%|█████████▎| 2028/2188 [22:09<01:45,  1.51it/s, Loss=4.49e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 93%|█████████▎| 2028/2188 [22:09<01:45,  1.51it/s, Loss=4.49e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 93%|█████████▎| 2029/2188 [22:10<01:41,  1.57it/s, Loss=4.49e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 93%|█████████▎| 2029/2188 [22:10<01:41,  1.57it/s, Loss=4.49e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 93%|█████████▎| 2030/2188 [22:10<01:36,  1.63it/s, Loss=4.49e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 93%|█████████▎| 2030/2188 [22:10<01:36,  1.63it/s, Loss=4.49e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 93%|█████████▎| 2031/2188 [22:11<01:35,  1.64it/s, Loss=4.49e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 93%|█████████▎| 2031/2188 [22:11<01:35,  1.64it/s, Loss=4.49e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 93%|█████████▎| 2032/2188 [22:11<01:34,  1.66it/s, Loss=4.49e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 93%|█████████▎| 2032/2188 [22:11<01:34,  1.66it/s, Loss=4.49e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 93%|█████████▎| 2033/2188 [22:12<01:34,  1.64it/s, Loss=4.49e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 93%|█████████▎| 2033/2188 [22:12<01:34,  1.64it/s, Loss=4.49e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 93%|█████████▎| 2034/2188 [22:13<01:31,  1.68it/s, Loss=4.49e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 93%|█████████▎| 2034/2188 [22:13<01:31,  1.68it/s, Loss=4.49e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 93%|█████████▎| 2035/2188 [22:13<01:30,  1.69it/s, Loss=4.49e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 93%|█████████▎| 2035/2188 [22:13<01:30,  1.69it/s, Loss=4.49e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 93%|█████████▎| 2036/2188 [22:14<01:28,  1.72it/s, Loss=4.49e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 93%|█████████▎| 2036/2188 [22:14<01:28,  1.72it/s, Loss=4.49e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 93%|█████████▎| 2037/2188 [22:14<01:28,  1.70it/s, Loss=4.49e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 93%|█████████▎| 2037/2188 [22:14<01:28,  1.70it/s, Loss=4.49e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 93%|█████████▎| 2038/2188 [22:15<01:26,  1.73it/s, Loss=4.49e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 93%|█████████▎| 2038/2188 [22:15<01:26,  1.73it/s, Loss=4.49e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 93%|█████████▎| 2039/2188 [22:15<01:25,  1.74it/s, Loss=4.49e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 93%|█████████▎| 2039/2188 [22:15<01:25,  1.74it/s, Loss=4.49e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 93%|█████████▎| 2040/2188 [22:16<01:25,  1.73it/s, Loss=4.49e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 93%|█████████▎| 2040/2188 [22:16<01:25,  1.73it/s, Loss=4.49e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 93%|█████████▎| 2041/2188 [22:17<01:24,  1.75it/s, Loss=4.49e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 93%|█████████▎| 2041/2188 [22:17<01:24,  1.75it/s, Loss=4.49e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 93%|█████████▎| 2042/2188 [22:17<01:24,  1.72it/s, Loss=4.49e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 93%|█████████▎| 2042/2188 [22:17<01:24,  1.72it/s, Loss=4.49e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 93%|█████████▎| 2043/2188 [22:18<01:31,  1.58it/s, Loss=4.49e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 93%|█████████▎| 2043/2188 [22:18<01:31,  1.58it/s, Loss=4.49e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 93%|█████████▎| 2044/2188 [22:19<01:41,  1.42it/s, Loss=4.49e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 93%|█████████▎| 2044/2188 [22:19<01:41,  1.42it/s, Loss=4.49e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 93%|█████████▎| 2045/2188 [22:20<01:48,  1.32it/s, Loss=4.49e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 93%|█████████▎| 2045/2188 [22:20<01:48,  1.32it/s, Loss=4.48e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 94%|█████████▎| 2046/2188 [22:21<01:53,  1.25it/s, Loss=4.48e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 94%|█████████▎| 2046/2188 [22:21<01:53,  1.25it/s, Loss=4.48e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 94%|█████████▎| 2047/2188 [22:21<01:47,  1.31it/s, Loss=4.48e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 94%|█████████▎| 2047/2188 [22:21<01:47,  1.31it/s, Loss=4.48e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 94%|█████████▎| 2048/2188 [22:22<01:38,  1.42it/s, Loss=4.48e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 94%|█████████▎| 2048/2188 [22:22<01:38,  1.42it/s, Loss=4.48e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 94%|█████████▎| 2049/2188 [22:22<01:32,  1.49it/s, Loss=4.48e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 94%|█████████▎| 2049/2188 [22:22<01:32,  1.49it/s, Loss=4.48e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 94%|█████████▎| 2050/2188 [22:23<01:30,  1.53it/s, Loss=4.48e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 94%|█████████▎| 2050/2188 [22:23<01:30,  1.53it/s, Loss=4.48e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 94%|█████████▎| 2051/2188 [22:24<01:27,  1.57it/s, Loss=4.48e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 94%|█████████▎| 2051/2188 [22:24<01:27,  1.57it/s, Loss=4.48e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 94%|█████████▍| 2052/2188 [22:24<01:23,  1.63it/s, Loss=4.48e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 94%|█████████▍| 2052/2188 [22:24<01:23,  1.63it/s, Loss=4.48e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 94%|█████████▍| 2053/2188 [22:25<01:21,  1.65it/s, Loss=4.48e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 94%|█████████▍| 2053/2188 [22:25<01:21,  1.65it/s, Loss=4.48e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 94%|█████████▍| 2054/2188 [22:25<01:21,  1.65it/s, Loss=4.48e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 94%|█████████▍| 2054/2188 [22:25<01:21,  1.65it/s, Loss=4.48e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 94%|█████████▍| 2055/2188 [22:26<01:20,  1.64it/s, Loss=4.48e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 94%|█████████▍| 2055/2188 [22:26<01:20,  1.64it/s, Loss=4.48e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 94%|█████████▍| 2056/2188 [22:27<01:19,  1.66it/s, Loss=4.48e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 94%|█████████▍| 2056/2188 [22:27<01:19,  1.66it/s, Loss=4.48e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 94%|█████████▍| 2057/2188 [22:27<01:17,  1.68it/s, Loss=4.48e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 94%|█████████▍| 2057/2188 [22:27<01:17,  1.68it/s, Loss=4.48e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 94%|█████████▍| 2058/2188 [22:28<01:16,  1.70it/s, Loss=4.48e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 94%|█████████▍| 2058/2188 [22:28<01:16,  1.70it/s, Loss=4.48e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 94%|█████████▍| 2059/2188 [22:28<01:15,  1.70it/s, Loss=4.48e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 94%|█████████▍| 2059/2188 [22:28<01:15,  1.70it/s, Loss=4.48e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 94%|█████████▍| 2060/2188 [22:29<01:14,  1.71it/s, Loss=4.48e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 94%|█████████▍| 2060/2188 [22:29<01:14,  1.71it/s, Loss=4.48e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 94%|█████████▍| 2061/2188 [22:30<01:16,  1.66it/s, Loss=4.48e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 94%|█████████▍| 2061/2188 [22:30<01:16,  1.66it/s, Loss=4.48e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 94%|█████████▍| 2062/2188 [22:30<01:13,  1.71it/s, Loss=4.48e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 94%|█████████▍| 2062/2188 [22:30<01:13,  1.71it/s, Loss=4.48e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 94%|█████████▍| 2063/2188 [22:31<01:12,  1.72it/s, Loss=4.48e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 94%|█████████▍| 2063/2188 [22:31<01:12,  1.72it/s, Loss=4.48e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 94%|█████████▍| 2064/2188 [22:32<01:23,  1.49it/s, Loss=4.48e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 94%|█████████▍| 2064/2188 [22:32<01:23,  1.49it/s, Loss=4.48e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 94%|█████████▍| 2065/2188 [22:32<01:30,  1.36it/s, Loss=4.48e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 94%|█████████▍| 2065/2188 [22:32<01:30,  1.36it/s, Loss=4.48e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 94%|█████████▍| 2066/2188 [22:33<01:32,  1.32it/s, Loss=4.48e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 94%|█████████▍| 2066/2188 [22:33<01:32,  1.32it/s, Loss=4.48e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 94%|█████████▍| 2067/2188 [22:34<01:40,  1.21it/s, Loss=4.48e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 94%|█████████▍| 2067/2188 [22:34<01:40,  1.21it/s, Loss=4.48e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 95%|█████████▍| 2068/2188 [22:35<01:30,  1.33it/s, Loss=4.48e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 95%|█████████▍| 2068/2188 [22:35<01:30,  1.33it/s, Loss=4.48e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 95%|█████████▍| 2069/2188 [22:35<01:23,  1.43it/s, Loss=4.48e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 95%|█████████▍| 2069/2188 [22:35<01:23,  1.43it/s, Loss=4.47e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 95%|█████████▍| 2070/2188 [22:36<01:18,  1.51it/s, Loss=4.47e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 95%|█████████▍| 2070/2188 [22:36<01:18,  1.51it/s, Loss=4.47e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 95%|█████████▍| 2071/2188 [22:37<01:14,  1.57it/s, Loss=4.47e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 95%|█████████▍| 2071/2188 [22:37<01:14,  1.57it/s, Loss=4.47e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 95%|█████████▍| 2072/2188 [22:37<01:11,  1.63it/s, Loss=4.47e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 95%|█████████▍| 2072/2188 [22:37<01:11,  1.63it/s, Loss=4.47e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 95%|█████████▍| 2073/2188 [22:38<01:10,  1.64it/s, Loss=4.47e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 95%|█████████▍| 2073/2188 [22:38<01:10,  1.64it/s, Loss=4.47e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 95%|█████████▍| 2074/2188 [22:38<01:08,  1.67it/s, Loss=4.47e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 95%|█████████▍| 2074/2188 [22:38<01:08,  1.67it/s, Loss=4.47e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 95%|█████████▍| 2075/2188 [22:39<01:06,  1.70it/s, Loss=4.47e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 95%|█████████▍| 2075/2188 [22:39<01:06,  1.70it/s, Loss=4.47e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 95%|█████████▍| 2076/2188 [22:39<01:05,  1.71it/s, Loss=4.47e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 95%|█████████▍| 2076/2188 [22:39<01:05,  1.71it/s, Loss=4.47e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 95%|█████████▍| 2077/2188 [22:40<01:05,  1.70it/s, Loss=4.47e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 95%|█████████▍| 2077/2188 [22:40<01:05,  1.70it/s, Loss=4.47e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 95%|█████████▍| 2078/2188 [22:41<01:06,  1.64it/s, Loss=4.47e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 95%|█████████▍| 2078/2188 [22:41<01:06,  1.64it/s, Loss=4.47e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 95%|█████████▌| 2079/2188 [22:41<01:04,  1.69it/s, Loss=4.47e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 95%|█████████▌| 2079/2188 [22:41<01:04,  1.69it/s, Loss=4.47e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 95%|█████████▌| 2080/2188 [22:42<01:05,  1.65it/s, Loss=4.47e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 95%|█████████▌| 2080/2188 [22:42<01:05,  1.65it/s, Loss=4.47e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 95%|█████████▌| 2081/2188 [22:42<01:05,  1.63it/s, Loss=4.47e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 95%|█████████▌| 2081/2188 [22:42<01:05,  1.63it/s, Loss=4.47e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 95%|█████████▌| 2082/2188 [22:43<01:02,  1.69it/s, Loss=4.47e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 95%|█████████▌| 2082/2188 [22:43<01:02,  1.69it/s, Loss=4.47e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 95%|█████████▌| 2083/2188 [22:44<01:01,  1.72it/s, Loss=4.47e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 95%|█████████▌| 2083/2188 [22:44<01:01,  1.72it/s, Loss=4.47e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 95%|█████████▌| 2084/2188 [22:44<01:00,  1.71it/s, Loss=4.47e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 95%|█████████▌| 2084/2188 [22:44<01:00,  1.71it/s, Loss=4.47e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 95%|█████████▌| 2085/2188 [22:45<01:06,  1.55it/s, Loss=4.47e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 95%|█████████▌| 2085/2188 [22:45<01:06,  1.55it/s, Loss=4.47e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 95%|█████████▌| 2086/2188 [22:46<01:12,  1.40it/s, Loss=4.47e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 95%|█████████▌| 2086/2188 [22:46<01:12,  1.40it/s, Loss=4.47e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 95%|█████████▌| 2087/2188 [22:47<01:17,  1.31it/s, Loss=4.47e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 95%|█████████▌| 2087/2188 [22:47<01:17,  1.31it/s, Loss=4.47e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 95%|█████████▌| 2088/2188 [22:48<01:20,  1.25it/s, Loss=4.47e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 95%|█████████▌| 2088/2188 [22:48<01:20,  1.25it/s, Loss=4.47e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 95%|█████████▌| 2089/2188 [22:48<01:13,  1.34it/s, Loss=4.47e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 95%|█████████▌| 2089/2188 [22:48<01:13,  1.34it/s, Loss=4.46e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 96%|█████████▌| 2090/2188 [22:49<01:07,  1.45it/s, Loss=4.46e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 96%|█████████▌| 2090/2188 [22:49<01:07,  1.45it/s, Loss=4.46e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 96%|█████████▌| 2091/2188 [22:49<01:03,  1.52it/s, Loss=4.46e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 96%|█████████▌| 2091/2188 [22:49<01:03,  1.52it/s, Loss=4.46e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 96%|█████████▌| 2092/2188 [22:50<01:02,  1.55it/s, Loss=4.46e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 96%|█████████▌| 2092/2188 [22:50<01:02,  1.55it/s, Loss=4.46e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 96%|█████████▌| 2093/2188 [22:51<00:59,  1.59it/s, Loss=4.46e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 96%|█████████▌| 2093/2188 [22:51<00:59,  1.59it/s, Loss=4.46e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 96%|█████████▌| 2094/2188 [22:51<00:58,  1.62it/s, Loss=4.46e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 96%|█████████▌| 2094/2188 [22:51<00:58,  1.62it/s, Loss=4.46e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 96%|█████████▌| 2095/2188 [22:52<00:56,  1.64it/s, Loss=4.46e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 96%|█████████▌| 2095/2188 [22:52<00:56,  1.64it/s, Loss=4.46e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 96%|█████████▌| 2096/2188 [22:52<00:55,  1.67it/s, Loss=4.46e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 96%|█████████▌| 2096/2188 [22:52<00:55,  1.67it/s, Loss=4.46e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 96%|█████████▌| 2097/2188 [22:53<00:53,  1.70it/s, Loss=4.46e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 96%|█████████▌| 2097/2188 [22:53<00:53,  1.70it/s, Loss=4.46e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 96%|█████████▌| 2098/2188 [22:53<00:52,  1.72it/s, Loss=4.46e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 96%|█████████▌| 2098/2188 [22:53<00:52,  1.72it/s, Loss=4.46e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 96%|█████████▌| 2099/2188 [22:54<00:51,  1.73it/s, Loss=4.46e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 96%|█████████▌| 2099/2188 [22:54<00:51,  1.73it/s, Loss=4.46e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 96%|█████████▌| 2100/2188 [22:55<00:51,  1.71it/s, Loss=4.46e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 96%|█████████▌| 2100/2188 [22:55<00:51,  1.71it/s, Loss=4.46e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 96%|█████████▌| 2101/2188 [22:55<00:49,  1.74it/s, Loss=4.46e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 96%|█████████▌| 2101/2188 [22:55<00:49,  1.74it/s, Loss=4.46e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 96%|█████████▌| 2102/2188 [22:56<00:50,  1.72it/s, Loss=4.46e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 96%|█████████▌| 2102/2188 [22:56<00:50,  1.72it/s, Loss=4.46e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 96%|█████████▌| 2103/2188 [22:56<00:49,  1.72it/s, Loss=4.46e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 96%|█████████▌| 2103/2188 [22:56<00:49,  1.72it/s, Loss=4.46e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 96%|█████████▌| 2104/2188 [22:57<00:48,  1.73it/s, Loss=4.46e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 96%|█████████▌| 2104/2188 [22:57<00:48,  1.73it/s, Loss=4.45e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 96%|█████████▌| 2105/2188 [22:58<00:48,  1.72it/s, Loss=4.45e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 96%|█████████▌| 2105/2188 [22:58<00:48,  1.72it/s, Loss=4.45e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 96%|█████████▋| 2106/2188 [22:58<00:51,  1.59it/s, Loss=4.45e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 96%|█████████▋| 2106/2188 [22:58<00:51,  1.59it/s, Loss=4.45e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 96%|█████████▋| 2107/2188 [22:59<01:01,  1.31it/s, Loss=4.45e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 96%|█████████▋| 2107/2188 [22:59<01:01,  1.31it/s, Loss=4.46e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 96%|█████████▋| 2108/2188 [23:00<01:05,  1.23it/s, Loss=4.46e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 96%|█████████▋| 2108/2188 [23:00<01:05,  1.23it/s, Loss=4.46e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 96%|█████████▋| 2109/2188 [23:01<01:06,  1.19it/s, Loss=4.46e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 96%|█████████▋| 2109/2188 [23:01<01:06,  1.19it/s, Loss=4.46e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 96%|█████████▋| 2110/2188 [23:02<01:01,  1.28it/s, Loss=4.46e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 96%|█████████▋| 2110/2188 [23:02<01:01,  1.28it/s, Loss=4.46e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 96%|█████████▋| 2111/2188 [23:02<00:55,  1.38it/s, Loss=4.46e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 96%|█████████▋| 2111/2188 [23:02<00:55,  1.38it/s, Loss=4.46e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 97%|█████████▋| 2112/2188 [23:03<00:52,  1.46it/s, Loss=4.46e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 97%|█████████▋| 2112/2188 [23:03<00:52,  1.46it/s, Loss=4.46e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 97%|█████████▋| 2113/2188 [23:04<00:49,  1.51it/s, Loss=4.46e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 97%|█████████▋| 2113/2188 [23:04<00:49,  1.51it/s, Loss=4.46e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 97%|█████████▋| 2114/2188 [23:04<00:46,  1.59it/s, Loss=4.46e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 97%|█████████▋| 2114/2188 [23:04<00:46,  1.59it/s, Loss=4.46e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 97%|█████████▋| 2115/2188 [23:05<00:44,  1.64it/s, Loss=4.46e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 97%|█████████▋| 2115/2188 [23:05<00:44,  1.64it/s, Loss=4.45e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 97%|█████████▋| 2116/2188 [23:05<00:43,  1.67it/s, Loss=4.45e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 97%|█████████▋| 2116/2188 [23:05<00:43,  1.67it/s, Loss=4.45e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 97%|█████████▋| 2117/2188 [23:06<00:41,  1.71it/s, Loss=4.45e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 97%|█████████▋| 2117/2188 [23:06<00:41,  1.71it/s, Loss=4.45e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 97%|█████████▋| 2118/2188 [23:06<00:40,  1.71it/s, Loss=4.45e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 97%|█████████▋| 2118/2188 [23:06<00:40,  1.71it/s, Loss=4.45e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 97%|█████████▋| 2119/2188 [23:07<00:40,  1.71it/s, Loss=4.45e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 97%|█████████▋| 2119/2188 [23:07<00:40,  1.71it/s, Loss=4.45e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 97%|█████████▋| 2120/2188 [23:08<00:40,  1.69it/s, Loss=4.45e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 97%|█████████▋| 2120/2188 [23:08<00:40,  1.69it/s, Loss=4.45e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 97%|█████████▋| 2121/2188 [23:08<00:39,  1.70it/s, Loss=4.45e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 97%|█████████▋| 2121/2188 [23:08<00:39,  1.70it/s, Loss=4.45e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 97%|█████████▋| 2122/2188 [23:09<00:38,  1.72it/s, Loss=4.45e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 97%|█████████▋| 2122/2188 [23:09<00:38,  1.72it/s, Loss=4.45e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 97%|█████████▋| 2123/2188 [23:09<00:38,  1.70it/s, Loss=4.45e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 97%|█████████▋| 2123/2188 [23:09<00:38,  1.70it/s, Loss=4.45e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 97%|█████████▋| 2124/2188 [23:10<00:36,  1.73it/s, Loss=4.45e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 97%|█████████▋| 2124/2188 [23:10<00:36,  1.73it/s, Loss=4.45e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 97%|█████████▋| 2125/2188 [23:10<00:36,  1.74it/s, Loss=4.45e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 97%|█████████▋| 2125/2188 [23:10<00:36,  1.74it/s, Loss=4.45e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 97%|█████████▋| 2126/2188 [23:11<00:36,  1.69it/s, Loss=4.45e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 97%|█████████▋| 2126/2188 [23:11<00:36,  1.69it/s, Loss=4.45e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 97%|█████████▋| 2127/2188 [23:12<00:40,  1.52it/s, Loss=4.45e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 97%|█████████▋| 2127/2188 [23:12<00:40,  1.52it/s, Loss=4.45e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 97%|█████████▋| 2128/2188 [23:13<00:42,  1.40it/s, Loss=4.45e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 97%|█████████▋| 2128/2188 [23:13<00:42,  1.40it/s, Loss=4.45e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 97%|█████████▋| 2129/2188 [23:14<00:45,  1.29it/s, Loss=4.45e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 97%|█████████▋| 2129/2188 [23:14<00:45,  1.29it/s, Loss=4.45e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 97%|█████████▋| 2130/2188 [23:15<00:47,  1.23it/s, Loss=4.45e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 97%|█████████▋| 2130/2188 [23:15<00:47,  1.23it/s, Loss=4.45e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 97%|█████████▋| 2131/2188 [23:15<00:42,  1.34it/s, Loss=4.45e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 97%|█████████▋| 2131/2188 [23:15<00:42,  1.34it/s, Loss=4.45e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 97%|█████████▋| 2132/2188 [23:16<00:39,  1.43it/s, Loss=4.45e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 97%|█████████▋| 2132/2188 [23:16<00:39,  1.43it/s, Loss=4.45e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 97%|█████████▋| 2133/2188 [23:16<00:35,  1.53it/s, Loss=4.45e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 97%|█████████▋| 2133/2188 [23:16<00:35,  1.53it/s, Loss=4.44e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 98%|█████████▊| 2134/2188 [23:17<00:34,  1.56it/s, Loss=4.44e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 98%|█████████▊| 2134/2188 [23:17<00:34,  1.56it/s, Loss=4.44e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 98%|█████████▊| 2135/2188 [23:18<00:32,  1.61it/s, Loss=4.44e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 98%|█████████▊| 2135/2188 [23:18<00:32,  1.61it/s, Loss=4.44e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 98%|█████████▊| 2136/2188 [23:18<00:31,  1.67it/s, Loss=4.44e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 98%|█████████▊| 2136/2188 [23:18<00:31,  1.67it/s, Loss=4.44e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 98%|█████████▊| 2137/2188 [23:19<00:30,  1.68it/s, Loss=4.44e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 98%|█████████▊| 2137/2188 [23:19<00:30,  1.68it/s, Loss=4.44e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 98%|█████████▊| 2138/2188 [23:19<00:29,  1.69it/s, Loss=4.44e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 98%|█████████▊| 2138/2188 [23:19<00:29,  1.69it/s, Loss=4.44e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 98%|█████████▊| 2139/2188 [23:20<00:28,  1.73it/s, Loss=4.44e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 98%|█████████▊| 2139/2188 [23:20<00:28,  1.73it/s, Loss=4.44e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 98%|█████████▊| 2140/2188 [23:20<00:27,  1.75it/s, Loss=4.44e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 98%|█████████▊| 2140/2188 [23:20<00:27,  1.75it/s, Loss=4.44e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 98%|█████████▊| 2141/2188 [23:21<00:27,  1.73it/s, Loss=4.44e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 98%|█████████▊| 2141/2188 [23:21<00:27,  1.73it/s, Loss=4.44e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 98%|█████████▊| 2142/2188 [23:22<00:26,  1.72it/s, Loss=4.44e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 98%|█████████▊| 2142/2188 [23:22<00:26,  1.72it/s, Loss=4.44e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 98%|█████████▊| 2143/2188 [23:22<00:25,  1.75it/s, Loss=4.44e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 98%|█████████▊| 2143/2188 [23:22<00:25,  1.75it/s, Loss=4.44e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 98%|█████████▊| 2144/2188 [23:23<00:24,  1.76it/s, Loss=4.44e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 98%|█████████▊| 2144/2188 [23:23<00:24,  1.76it/s, Loss=4.44e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 98%|█████████▊| 2145/2188 [23:23<00:24,  1.78it/s, Loss=4.44e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 98%|█████████▊| 2145/2188 [23:23<00:24,  1.78it/s, Loss=4.44e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 98%|█████████▊| 2146/2188 [23:24<00:23,  1.76it/s, Loss=4.44e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 98%|█████████▊| 2146/2188 [23:24<00:23,  1.76it/s, Loss=4.44e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 98%|█████████▊| 2147/2188 [23:24<00:24,  1.66it/s, Loss=4.44e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 98%|█████████▊| 2147/2188 [23:24<00:24,  1.66it/s, Loss=4.44e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 98%|█████████▊| 2148/2188 [23:25<00:27,  1.45it/s, Loss=4.44e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 98%|█████████▊| 2148/2188 [23:25<00:27,  1.45it/s, Loss=4.44e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 98%|█████████▊| 2149/2188 [23:26<00:30,  1.30it/s, Loss=4.44e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 98%|█████████▊| 2149/2188 [23:26<00:30,  1.30it/s, Loss=4.44e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 98%|█████████▊| 2150/2188 [23:27<00:31,  1.20it/s, Loss=4.44e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 98%|█████████▊| 2150/2188 [23:27<00:31,  1.20it/s, Loss=4.44e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 98%|█████████▊| 2151/2188 [23:28<00:30,  1.21it/s, Loss=4.44e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 98%|█████████▊| 2151/2188 [23:28<00:30,  1.21it/s, Loss=4.44e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 98%|█████████▊| 2152/2188 [23:29<00:27,  1.32it/s, Loss=4.44e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 98%|█████████▊| 2152/2188 [23:29<00:27,  1.32it/s, Loss=4.44e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 98%|█████████▊| 2153/2188 [23:29<00:24,  1.43it/s, Loss=4.44e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 98%|█████████▊| 2153/2188 [23:29<00:24,  1.43it/s, Loss=4.44e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 98%|█████████▊| 2154/2188 [23:30<00:23,  1.48it/s, Loss=4.44e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 98%|█████████▊| 2154/2188 [23:30<00:23,  1.48it/s, Loss=4.44e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 98%|█████████▊| 2155/2188 [23:30<00:21,  1.55it/s, Loss=4.44e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 98%|█████████▊| 2155/2188 [23:30<00:21,  1.55it/s, Loss=4.44e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 99%|█████████▊| 2156/2188 [23:31<00:20,  1.53it/s, Loss=4.44e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 99%|█████████▊| 2156/2188 [23:31<00:20,  1.53it/s, Loss=4.44e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 99%|█████████▊| 2157/2188 [23:32<00:19,  1.57it/s, Loss=4.44e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 99%|█████████▊| 2157/2188 [23:32<00:19,  1.57it/s, Loss=4.44e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 99%|█████████▊| 2158/2188 [23:32<00:18,  1.61it/s, Loss=4.44e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 99%|█████████▊| 2158/2188 [23:32<00:18,  1.61it/s, Loss=4.44e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 99%|█████████▊| 2159/2188 [23:33<00:17,  1.66it/s, Loss=4.44e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 99%|█████████▊| 2159/2188 [23:33<00:17,  1.66it/s, Loss=4.44e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 99%|█████████▊| 2160/2188 [23:33<00:16,  1.70it/s, Loss=4.44e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 99%|█████████▊| 2160/2188 [23:33<00:16,  1.70it/s, Loss=4.44e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 99%|█████████▉| 2161/2188 [23:34<00:15,  1.72it/s, Loss=4.44e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 99%|█████████▉| 2161/2188 [23:34<00:15,  1.72it/s, Loss=4.44e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 99%|█████████▉| 2162/2188 [23:35<00:15,  1.67it/s, Loss=4.44e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 99%|█████████▉| 2162/2188 [23:35<00:15,  1.67it/s, Loss=4.44e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 99%|█████████▉| 2163/2188 [23:35<00:15,  1.63it/s, Loss=4.44e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 99%|█████████▉| 2163/2188 [23:35<00:15,  1.63it/s, Loss=4.44e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 99%|█████████▉| 2164/2188 [23:36<00:14,  1.63it/s, Loss=4.44e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 99%|█████████▉| 2164/2188 [23:36<00:14,  1.63it/s, Loss=4.44e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 99%|█████████▉| 2165/2188 [23:36<00:13,  1.67it/s, Loss=4.44e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 99%|█████████▉| 2165/2188 [23:36<00:13,  1.67it/s, Loss=4.44e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 99%|█████████▉| 2166/2188 [23:37<00:12,  1.70it/s, Loss=4.44e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 99%|█████████▉| 2166/2188 [23:37<00:12,  1.70it/s, Loss=4.44e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 99%|█████████▉| 2167/2188 [23:38<00:12,  1.71it/s, Loss=4.44e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 99%|█████████▉| 2167/2188 [23:38<00:12,  1.71it/s, Loss=4.44e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 99%|█████████▉| 2168/2188 [23:38<00:12,  1.66it/s, Loss=4.44e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 99%|█████████▉| 2168/2188 [23:38<00:12,  1.66it/s, Loss=4.44e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 99%|█████████▉| 2169/2188 [23:39<00:13,  1.40it/s, Loss=4.44e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 99%|█████████▉| 2169/2188 [23:39<00:13,  1.40it/s, Loss=4.44e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 99%|█████████▉| 2170/2188 [23:40<00:13,  1.30it/s, Loss=4.44e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 99%|█████████▉| 2170/2188 [23:40<00:13,  1.30it/s, Loss=4.44e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 99%|█████████▉| 2171/2188 [23:41<00:13,  1.22it/s, Loss=4.44e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 99%|█████████▉| 2171/2188 [23:41<00:13,  1.22it/s, Loss=4.44e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 99%|█████████▉| 2172/2188 [23:42<00:12,  1.23it/s, Loss=4.44e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 99%|█████████▉| 2172/2188 [23:42<00:12,  1.23it/s, Loss=4.44e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 99%|█████████▉| 2173/2188 [23:42<00:11,  1.36it/s, Loss=4.44e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 99%|█████████▉| 2173/2188 [23:42<00:11,  1.36it/s, Loss=4.44e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 99%|█████████▉| 2174/2188 [23:43<00:09,  1.44it/s, Loss=4.44e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 99%|█████████▉| 2174/2188 [23:43<00:09,  1.44it/s, Loss=4.44e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 99%|█████████▉| 2175/2188 [23:44<00:08,  1.53it/s, Loss=4.44e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 99%|█████████▉| 2175/2188 [23:44<00:08,  1.53it/s, Loss=4.44e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 99%|█████████▉| 2176/2188 [23:44<00:07,  1.60it/s, Loss=4.44e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 99%|█████████▉| 2176/2188 [23:44<00:07,  1.60it/s, Loss=4.44e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 99%|█████████▉| 2177/2188 [23:45<00:06,  1.66it/s, Loss=4.44e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 99%|█████████▉| 2177/2188 [23:45<00:06,  1.66it/s, Loss=4.44e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "100%|█████████▉| 2178/2188 [23:45<00:05,  1.69it/s, Loss=4.44e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "100%|█████████▉| 2178/2188 [23:45<00:05,  1.69it/s, Loss=4.44e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "100%|█████████▉| 2179/2188 [23:46<00:05,  1.69it/s, Loss=4.44e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "100%|█████████▉| 2179/2188 [23:46<00:05,  1.69it/s, Loss=4.44e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "100%|█████████▉| 2180/2188 [23:46<00:04,  1.71it/s, Loss=4.44e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "100%|█████████▉| 2180/2188 [23:46<00:04,  1.71it/s, Loss=4.44e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "100%|█████████▉| 2181/2188 [23:47<00:04,  1.72it/s, Loss=4.44e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "100%|█████████▉| 2181/2188 [23:47<00:04,  1.72it/s, Loss=4.43e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "100%|█████████▉| 2182/2188 [23:48<00:03,  1.74it/s, Loss=4.43e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "100%|█████████▉| 2182/2188 [23:48<00:03,  1.74it/s, Loss=4.43e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "100%|█████████▉| 2183/2188 [23:48<00:02,  1.73it/s, Loss=4.43e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "100%|█████████▉| 2183/2188 [23:48<00:02,  1.73it/s, Loss=4.43e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "100%|█████████▉| 2184/2188 [23:49<00:02,  1.68it/s, Loss=4.43e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "100%|█████████▉| 2184/2188 [23:49<00:02,  1.68it/s, Loss=4.43e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "100%|█████████▉| 2185/2188 [23:49<00:01,  1.68it/s, Loss=4.43e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "100%|█████████▉| 2185/2188 [23:49<00:01,  1.68it/s, Loss=4.43e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "100%|█████████▉| 2186/2188 [23:50<00:01,  1.71it/s, Loss=4.43e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "100%|█████████▉| 2186/2188 [23:50<00:01,  1.71it/s, Loss=4.43e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "100%|█████████▉| 2187/2188 [23:50<00:00,  1.71it/s, Loss=4.43e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "100%|█████████▉| 2187/2188 [23:50<00:00,  1.71it/s, Loss=4.43e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "100%|██████████| 2188/2188 [23:51<00:00,  2.02it/s, Loss=4.43e+4]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "100%|██████████| 2188/2188 [23:51<00:00,  1.53it/s, Loss=4.43e+4]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "====> Train Epoch: 0 Loss: 44319.1075\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 938/938 [08:57<00:00,  1.74it/s, Loss=2.72e+4]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "====> Test Epoch: 0 Loss: 27167.6559\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2188/2188 [22:30<00:00,  1.62it/s, Loss=3.61e+4]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "====> Train Epoch: 1 Loss: 36089.1224\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 938/938 [08:57<00:00,  1.74it/s, Loss=2.72e+4]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "====> Test Epoch: 1 Loss: 27230.5646\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2188/2188 [22:49<00:00,  1.60it/s, Loss=3.6e+4]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "====> Train Epoch: 2 Loss: 36046.2053\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 938/938 [09:07<00:00,  1.71it/s, Loss=2.71e+4]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "====> Test Epoch: 2 Loss: 27120.0991\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2188/2188 [22:46<00:00,  1.60it/s, Loss=3.6e+4]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "====> Train Epoch: 3 Loss: 36032.4094\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 938/938 [09:06<00:00,  1.72it/s, Loss=2.72e+4]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "====> Test Epoch: 3 Loss: 27187.1959\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2188/2188 [22:54<00:00,  1.59it/s, Loss=3.6e+4]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "====> Train Epoch: 4 Loss: 36046.7205\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 938/938 [09:06<00:00,  1.72it/s, Loss=2.72e+4]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "====> Test Epoch: 4 Loss: 27170.8735\n",
            "Train time: 6891.822069883347\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "\n",
        "is_best, best_loss = False, np.inf\n",
        "train_losses = np.zeros(epochs)\n",
        "if not no_test:\n",
        "    test_losses  = np.zeros(epochs)\n",
        "train_times = np.zeros(epochs)\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    start_time = time.time()\n",
        "    train_loss = train(epoch)\n",
        "    end_time = time.time()\n",
        "    train_losses[epoch] = train_loss\n",
        "    train_times[epoch] = start_time - end_time\n",
        "\n",
        "    if not no_test:\n",
        "        test_loss = test(epoch)\n",
        "        test_losses[epoch] = test_loss\n",
        "        is_best = test_loss < best_loss\n",
        "        best_loss = min(test_loss, best_loss)\n",
        "    else:\n",
        "        is_best = train_loss < best_loss\n",
        "        best_loss = min(train_loss, best_loss)\n",
        "\n",
        "    save_checkpoint({\n",
        "        'model_state_dict': model.state_dict(),\n",
        "        'epoch': epoch,\n",
        "    }, is_best, folder=out_dir)\n",
        "\n",
        "    np.save(os.path.join(out_dir, 'train_losses.npy'), train_losses)\n",
        "    np.save(os.path.join(out_dir, 'train_times.npy'), train_times)\n",
        "\n",
        "    if not no_test:\n",
        "        np.save(os.path.join(out_dir, 'test_losses.npy'),  test_losses)\n",
        "        \n",
        "print(f'Train time: {np.abs(train_times).sum()}')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4ad71631-9b79-4fcb-bc96-7ce5ad692ecc",
      "metadata": {
        "id": "4ad71631-9b79-4fcb-bc96-7ce5ad692ecc"
      },
      "source": [
        "## Inference & Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a4bb4d48-887f-4a32-b8a7-49905ab42809",
      "metadata": {
        "id": "a4bb4d48-887f-4a32-b8a7-49905ab42809",
        "outputId": "0e43d455-aa2c-410b-e9e3-f01326b62180"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 329/329 [00:14<00:00, 23.38it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "y_pred: (array([0., 1.]), array([ 63266, 271724]))\n",
            "y: (array([0., 1.]), array([119446, 215544]))\n",
            "Missing Imputation Accuracy from samples: 0.6965103435923461\n",
            "AUC: 0.70\n",
            "[[ 40523  78923]\n",
            " [ 22743 192801]]\n",
            "Infer time: 14.074613332748413\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "def get_infer_dict(loader):\n",
        "    model.eval()\n",
        "    infer_dict = {}\n",
        "    \n",
        "    start_time = time.time()\n",
        "\n",
        "    with torch.no_grad(): \n",
        "        ability_mus, item_feat_mus = [], []\n",
        "        ability_logvars, item_feat_logvars = [], []\n",
        "\n",
        "        pbar = tqdm(total=len(loader))\n",
        "        for _, response, _, mask in loader:\n",
        "            mb = response.size(0)\n",
        "            response = response.to(device)\n",
        "            mask = mask.long().to(device)\n",
        "\n",
        "            _, ability_mu, ability_logvar, _, item_feat_mu, item_feat_logvar = \\\n",
        "                model.encode(response, mask)\n",
        "\n",
        "            ability_mus.append(ability_mu.cpu())\n",
        "            ability_logvars.append(ability_logvar.cpu())\n",
        "\n",
        "            item_feat_mus.append(item_feat_mu.cpu())\n",
        "            item_feat_logvars.append(item_feat_logvar.cpu())\n",
        "\n",
        "            pbar.update()\n",
        "\n",
        "        ability_mus = torch.cat(ability_mus, dim=0)\n",
        "        ability_logvars = torch.cat(ability_logvars, dim=0)\n",
        "        pbar.close()\n",
        "\n",
        "    infer_dict['ability_mu'] = ability_mus\n",
        "    infer_dict['ability_logvar'] = ability_logvars\n",
        "    infer_dict['item_feat_mu'] = item_feat_mu\n",
        "    infer_dict['item_feat_logvar'] = item_feat_logvar\n",
        "\n",
        "    return infer_dict\n",
        "\n",
        "def sample_posterior_predictive(loader):\n",
        "    model.eval()\n",
        "    meter = AverageMeter()\n",
        "    pbar = tqdm(total=len(loader))\n",
        "    \n",
        "    start_time = time.time()\n",
        "\n",
        "    with torch.no_grad():\n",
        "\n",
        "        response_sample_set = []\n",
        "\n",
        "        for _, response, _, mask in loader:\n",
        "            mb = response.size(0)\n",
        "            response = response.to(device)\n",
        "            mask = mask.long().to(device)\n",
        "\n",
        "            _, ability_mu, ability_logvar, _, item_feat_mu, item_feat_logvar = \\\n",
        "                model.encode(response, mask)\n",
        "\n",
        "            ability_scale = torch.exp(0.5 * ability_logvar)\n",
        "            item_feat_scale = torch.exp(0.5 * item_feat_logvar)\n",
        "\n",
        "            ability_posterior = dist.Normal(ability_mu, ability_scale)\n",
        "            item_feat_posterior = dist.Normal(item_feat_mu, item_feat_scale)\n",
        "\n",
        "            ability_samples = ability_posterior.sample([num_posterior_samples])\n",
        "            item_feat_samples = item_feat_posterior.sample([num_posterior_samples])\n",
        "\n",
        "            response_samples = []\n",
        "            for i in range(num_posterior_samples):\n",
        "                ability_i = ability_samples[i]\n",
        "                item_feat_i = item_feat_samples[i]\n",
        "                response_i = model.decode(ability_i, item_feat_i).cpu()\n",
        "                response_samples.append(response_i)\n",
        "            response_samples = torch.stack(response_samples)\n",
        "            response_sample_set.append(response_samples)\n",
        "\n",
        "            pbar.update()\n",
        "\n",
        "        response_sample_set = torch.cat(response_sample_set, dim=1)\n",
        "\n",
        "        pbar.close()\n",
        "        \n",
        "    end_time = time.time()\n",
        "\n",
        "    return {'response': response_sample_set, 'infer_time': end_time - start_time}\n",
        "\n",
        "def sample_posterior_mean(loader):\n",
        "    model.eval()\n",
        "    meter = AverageMeter()\n",
        "    pbar = tqdm(total=len(loader))\n",
        "    \n",
        "    start_time = time.time()\n",
        "    \n",
        "    with torch.no_grad():\n",
        "\n",
        "        response_sample_set = []\n",
        "\n",
        "        for _, response, _, mask in loader:\n",
        "            mb = response.size(0)\n",
        "            response = response.to(device)\n",
        "            mask = mask.long().to(device)\n",
        "\n",
        "            _, ability_mu, _, _, item_feat_mu, _ = \\\n",
        "                model.encode(response, mask)\n",
        "\n",
        "            response_sample = model.decode(ability_mu, item_feat_mu).cpu()\n",
        "            response_sample_set.append(response_sample.unsqueeze(0))\n",
        "\n",
        "            pbar.update()\n",
        "\n",
        "        response_sample_set = torch.cat(response_sample_set, dim=1)\n",
        "\n",
        "        pbar.close()\n",
        "    \n",
        "    end_time = time.time()\n",
        "    \n",
        "    return {'response': response_sample_set, 'infer_time': end_time - start_time}\n",
        "\n",
        "def run_inference_new_loader(train=False):\n",
        "    dataset = train_dataset if train else test_dataset\n",
        "    loader = torch.utils.data.DataLoader(\n",
        "        dataset,\n",
        "        batch_size = batch_size, \n",
        "        shuffle = False,\n",
        "    )\n",
        "    for checkpoint_name in ['model_best.pth.tar']:\n",
        "        checkpoint = torch.load(os.path.join(out_dir, checkpoint_name))\n",
        "        model.load_state_dict(checkpoint['model_state_dict'])\n",
        "        posterior_mean_samples = sample_posterior_mean(loader)\n",
        "        checkpoint['posterior_mean_samples'] = posterior_mean_samples\n",
        "        y_pred_prob = posterior_mean_samples['response'].squeeze(0).squeeze(2).numpy()\n",
        "        y_pred = np.round(y_pred_prob)\n",
        "\n",
        "\n",
        "def run_inference(train=True):\n",
        "    dataset = train_dataset if train else test_dataset\n",
        "    loader = torch.utils.data.DataLoader(\n",
        "        dataset,\n",
        "        batch_size = batch_size, \n",
        "        shuffle = False,\n",
        "    )\n",
        "    \n",
        "    # for checkpoint_name in ['checkpoint.pth.tar', 'model_best.pth.tar']:\n",
        "    for checkpoint_name in ['model_best.pth.tar']:\n",
        "        checkpoint = torch.load(os.path.join(out_dir, checkpoint_name))\n",
        "        model.load_state_dict(checkpoint['model_state_dict'])\n",
        "\n",
        "        # infer_dict = get_infer_dict(loader)\n",
        "        # checkpoint['infer_dict'] = infer_dict\n",
        "        \n",
        "#         posterior_predict_samples = sample_posterior_predictive(loader)\n",
        "#         checkpoint['posterior_predict_samples'] = posterior_predict_samples\n",
        "        \n",
        "#         if artificial_missing_perc > 0:\n",
        "#             missing_indices = dataset.missing_indices\n",
        "#             missing_labels = dataset.missing_labels\n",
        "            \n",
        "#             if np.ndim(missing_labels) == 1:\n",
        "#                 missing_labels = np.round(missing_labels[:, np.newaxis])\n",
        "                \n",
        "#             y_pred_prob = posterior_predict_samples['response'].mean(0)\n",
        "#             y_pred = np.round(y_pred_prob)\n",
        "            \n",
        "#             correct, count = 0, 0\n",
        "#             predicted_labels = []\n",
        "#             predicted_label_probs = []\n",
        "#             for missing_index, missing_label in zip(missing_indices, missing_labels):\n",
        "#                 predicted_label = y_pred[missing_index[0], missing_index[1]]\n",
        "#                 if predicted_label.item() == missing_label[0]:\n",
        "#                     correct += 1\n",
        "#                 count += 1\n",
        "#                 predicted_labels.append(predicted_label.item())\n",
        "#                 predicted_label_probs.append(y_pred_prob[missing_index[0], missing_index[1]])\n",
        "            \n",
        "#             print('y_pred:', np.unique(predicted_labels, return_counts=True))\n",
        "#             print('y:', np.unique(missing_labels.flatten(), return_counts=True))\n",
        "            \n",
        "#             missing_imputation_accuracy = correct / float(count)\n",
        "#             checkpoint['missing_imputation_accuracy'] = missing_imputation_accuracy\n",
        "#             print(f'Missing Imputation Accuracy from samples: {missing_imputation_accuracy}')\n",
        "            \n",
        "#             auc = roc_auc_score(missing_labels.flatten(), predicted_label_probs)\n",
        "#             print(\"AUC: {:.2f}\".format(auc))\n",
        "            \n",
        "#             cm = confusion_matrix(missing_labels.flatten(), predicted_labels)\n",
        "#             print(cm)\n",
        "#             disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[0, 1])\n",
        "#             disp.plot()\n",
        "            \n",
        "#             print(f'Infer time:', posterior_predict_samples['infer_time'])\n",
        "\n",
        "        posterior_mean_samples = sample_posterior_mean(loader)\n",
        "        checkpoint['posterior_mean_samples'] = posterior_mean_samples\n",
        "        \n",
        "        if artificial_missing_perc > 0:\n",
        "            missing_indices = dataset.missing_indices\n",
        "            missing_labels = dataset.missing_labels\n",
        "            \n",
        "            if np.ndim(missing_labels) == 1:\n",
        "                missing_labels = np.round(missing_labels[:, np.newaxis])\n",
        "                \n",
        "            y_pred_prob = posterior_mean_samples['response'].squeeze(0).squeeze(2).numpy()\n",
        "            y_pred = np.round(y_pred_prob)\n",
        "            \n",
        "            correct, count = 0, 0\n",
        "            predicted_labels = []\n",
        "            predicted_label_probs = []\n",
        "            for missing_index, missing_label in zip(missing_indices, missing_labels):\n",
        "                predicted_label = y_pred[missing_index[0], missing_index[1]]\n",
        "                if predicted_label.item() == missing_label[0]:\n",
        "                    correct += 1\n",
        "                count += 1\n",
        "                predicted_labels.append(predicted_label.item())\n",
        "                predicted_label_probs.append(y_pred_prob[missing_index[0], missing_index[1]])\n",
        "            \n",
        "            print('y_pred:', np.unique(predicted_labels, return_counts=True))\n",
        "            print('y:', np.unique(missing_labels.flatten(), return_counts=True))\n",
        "            \n",
        "            missing_imputation_accuracy = correct / float(count)\n",
        "            checkpoint['missing_imputation_accuracy'] = missing_imputation_accuracy\n",
        "            print(f'Missing Imputation Accuracy from samples: {missing_imputation_accuracy}')\n",
        "            \n",
        "            auc = roc_auc_score(missing_labels.flatten(), predicted_label_probs)\n",
        "            print(\"AUC: {:.2f}\".format(auc))\n",
        "            \n",
        "            cm = confusion_matrix(missing_labels.flatten(), predicted_labels)\n",
        "            print(cm)\n",
        "            disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[0, 1])\n",
        "            disp.plot()\n",
        "            \n",
        "            print(f'Infer time:', posterior_mean_samples['infer_time'])\n",
        "            \n",
        "            \n",
        "            \n",
        "        \n",
        "#         y_pred_prob = posterior_mean_samples['response'].squeeze(0).squeeze(2).numpy()\n",
        "#         y_pred = np.round(y_pred_prob)\n",
        "        \n",
        "#         y_prob = dataset.responses\n",
        "#         y = np.round(y_prob)\n",
        "        \n",
        "#         correct = (y_pred == y).sum()\n",
        "#         count = (y != MISSING_DATA).sum()\n",
        "#         accuracy = correct / float(count)\n",
        "#         checkpoint['accuracy_from_mean'] = accuracy\n",
        "#         print(f'Accuracy from mean: {accuracy}, Correct: {correct}, count: {count}')\n",
        "        \n",
        "#         mask = np.array(dataset.mask, dtype=bool)\n",
        "#         print('y_pred:', np.unique(y_pred[mask], return_counts=True))\n",
        "#         print('y:', np.unique(y, return_counts=True))\n",
        "        \n",
        "#         cm = confusion_matrix(y[mask].flatten(), y_pred[mask].flatten())\n",
        "#         print(cm)\n",
        "#         disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[0, 1])\n",
        "#         disp.plot()\n",
        "        \n",
        "#         auc = roc_auc_score(y[mask], y_pred_prob[mask])\n",
        "#         print(\"AUC: {:.2f}\".format(auc))\n",
        "        \n",
        "#         print(f'Infer time:', posterior_mean_samples['infer_time'])\n",
        "\n",
        "#         train_logp = get_log_marginal_density(data_loader)\n",
        "#         checkpoint['train_logp'] = train_logp\n",
        "\n",
        "#         if not no_test:\n",
        "#             test_logp = get_log_marginal_density(test_loader)\n",
        "#             checkpoint['test_logp'] = test_logp\n",
        "\n",
        "        torch.save(checkpoint, os.path.join(out_dir, checkpoint_name))\n",
        "\n",
        "run_inference(train=True)\n",
        "\n",
        "# Best\n",
        "# irt_model=2pl, ability_dim=8,\n",
        "# y_pred: (array([0., 1.]), array([ 63155, 271835]))\n",
        "# y: (array([0., 1.]), array([119446, 215544]))\n",
        "# Missing Imputation Accuracy from samples: 0.6971700647780531\n",
        "# AUC: 0.70\n",
        "# [[ 40578  78868]\n",
        "#  [ 22577 192967]]\n",
        "# Infer time: 11.841894388198853"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "10d5265b-8750-4d9b-b81e-a4083678269c",
      "metadata": {
        "id": "10d5265b-8750-4d9b-b81e-a4083678269c"
      },
      "source": [
        "# References\n",
        "1. https://github.com/mhw32/variational-item-response-theory-public"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.12"
    },
    "colab": {
      "provenance": []
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}