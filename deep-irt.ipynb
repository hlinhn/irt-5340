{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!git clone https://github.com/hlinhn/DeepIRT-tf2","metadata":{"execution":{"iopub.status.busy":"2023-04-08T19:11:57.107591Z","iopub.execute_input":"2023-04-08T19:11:57.108118Z","iopub.status.idle":"2023-04-08T19:11:59.063371Z","shell.execute_reply.started":"2023-04-08T19:11:57.108088Z","shell.execute_reply":"2023-04-08T19:11:59.062202Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Cloning into 'DeepIRT-tf2'...\nremote: Enumerating objects: 152, done.\u001b[K\nremote: Counting objects: 100% (43/43), done.\u001b[K\nremote: Compressing objects: 100% (29/29), done.\u001b[K\nremote: Total 152 (delta 23), reused 19 (delta 14), pack-reused 109\u001b[K\nReceiving objects: 100% (152/152), 4.15 MiB | 13.44 MiB/s, done.\nResolving deltas: 100% (74/74), done.\n","output_type":"stream"}]},{"cell_type":"raw","source":"!cd '/kaggle/working/DeepIRT-tf2' && git checkout ednet","metadata":{"execution":{"iopub.status.busy":"2023-04-08T19:12:31.283820Z","iopub.execute_input":"2023-04-08T19:12:31.284350Z","iopub.status.idle":"2023-04-08T19:12:32.457130Z","shell.execute_reply.started":"2023-04-08T19:12:31.284305Z","shell.execute_reply":"2023-04-08T19:12:32.455976Z"}}},{"cell_type":"code","source":"!cd '/kaggle/working/DeepIRT-tf2' && pip install -r requirements.txt","metadata":{"execution":{"iopub.status.busy":"2023-04-08T19:13:21.454826Z","iopub.execute_input":"2023-04-08T19:13:21.455181Z","iopub.status.idle":"2023-04-08T19:14:41.066374Z","shell.execute_reply.started":"2023-04-08T19:13:21.455149Z","shell.execute_reply":"2023-04-08T19:14:41.065159Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"Requirement already satisfied: absl-py==1.4.0 in /opt/conda/lib/python3.7/site-packages (from -r requirements.txt (line 1)) (1.4.0)\nCollecting astor==0.8.1\n  Downloading astor-0.8.1-py2.py3-none-any.whl (27 kB)\nRequirement already satisfied: certifi==2022.12.7 in /opt/conda/lib/python3.7/site-packages (from -r requirements.txt (line 3)) (2022.12.7)\nRequirement already satisfied: gast==0.4.0 in /opt/conda/lib/python3.7/site-packages (from -r requirements.txt (line 4)) (0.4.0)\nRequirement already satisfied: grpcio==1.51.1 in /opt/conda/lib/python3.7/site-packages (from -r requirements.txt (line 5)) (1.51.1)\nCollecting h5py==3.1.0\n  Downloading h5py-3.1.0-cp37-cp37m-manylinux1_x86_64.whl (4.0 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.0/4.0 MB\u001b[0m \u001b[31m43.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: joblib==1.2.0 in /opt/conda/lib/python3.7/site-packages (from -r requirements.txt (line 7)) (1.2.0)\nCollecting Keras-Applications==1.0.8\n  Downloading Keras_Applications-1.0.8-py3-none-any.whl (50 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.7/50.7 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting Keras-Preprocessing==1.1.2\n  Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.6/42.6 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting Markdown==3.1.1\n  Downloading Markdown-3.1.1-py2.py3-none-any.whl (87 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.8/87.8 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting mock==3.0.5\n  Downloading mock-3.0.5-py2.py3-none-any.whl (25 kB)\nRequirement already satisfied: numpy==1.21.6 in /opt/conda/lib/python3.7/site-packages (from -r requirements.txt (line 12)) (1.21.6)\nCollecting progress==1.6\n  Downloading progress-1.6.tar.gz (7.8 kB)\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hCollecting protobuf==3.19.6\n  Downloading protobuf-3.19.6-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m59.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: scikit-learn==1.0.2 in /opt/conda/lib/python3.7/site-packages (from -r requirements.txt (line 15)) (1.0.2)\nRequirement already satisfied: scipy==1.7.3 in /opt/conda/lib/python3.7/site-packages (from -r requirements.txt (line 16)) (1.7.3)\nCollecting six==1.15.0\n  Downloading six-1.15.0-py2.py3-none-any.whl (10 kB)\nCollecting tensorboard==2.9.1\n  Downloading tensorboard-2.9.1-py3-none-any.whl (5.8 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.8/5.8 MB\u001b[0m \u001b[31m69.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting tensorflow==2.9.0\n  Downloading tensorflow-2.9.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (511.7 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m511.7/511.7 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting tensorflow-estimator==2.9.0\n  Downloading tensorflow_estimator-2.9.0-py2.py3-none-any.whl (438 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m438.7/438.7 kB\u001b[0m \u001b[31m27.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: termcolor==2.2.0 in /opt/conda/lib/python3.7/site-packages (from -r requirements.txt (line 21)) (2.2.0)\nCollecting tf-slim==1.1.0\n  Downloading tf_slim-1.1.0-py2.py3-none-any.whl (352 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m352.1/352.1 kB\u001b[0m \u001b[31m21.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting Werkzeug==1.0.1\n  Downloading Werkzeug-1.0.1-py2.py3-none-any.whl (298 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m298.6/298.6 kB\u001b[0m \u001b[31m27.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: wrapt==1.14.1 in /opt/conda/lib/python3.7/site-packages (from -r requirements.txt (line 24)) (1.14.1)\nRequirement already satisfied: cached-property in /opt/conda/lib/python3.7/site-packages (from h5py==3.1.0->-r requirements.txt (line 6)) (1.5.2)\nRequirement already satisfied: setuptools>=36 in /opt/conda/lib/python3.7/site-packages (from Markdown==3.1.1->-r requirements.txt (line 10)) (59.8.0)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from scikit-learn==1.0.2->-r requirements.txt (line 15)) (3.1.0)\nRequirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /opt/conda/lib/python3.7/site-packages (from tensorboard==2.9.1->-r requirements.txt (line 18)) (0.4.6)\nRequirement already satisfied: wheel>=0.26 in /opt/conda/lib/python3.7/site-packages (from tensorboard==2.9.1->-r requirements.txt (line 18)) (0.38.4)\nRequirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard==2.9.1->-r requirements.txt (line 18)) (2.28.2)\nRequirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard==2.9.1->-r requirements.txt (line 18)) (1.8.1)\nRequirement already satisfied: google-auth<3,>=1.6.3 in /opt/conda/lib/python3.7/site-packages (from tensorboard==2.9.1->-r requirements.txt (line 18)) (1.35.0)\nRequirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard==2.9.1->-r requirements.txt (line 18)) (0.6.1)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.7/site-packages (from tensorflow==2.9.0->-r requirements.txt (line 19)) (23.0)\nCollecting flatbuffers<2,>=1.12\n  Downloading flatbuffers-1.12-py2.py3-none-any.whl (15 kB)\nRequirement already satisfied: libclang>=13.0.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow==2.9.0->-r requirements.txt (line 19)) (15.0.6.1)\nRequirement already satisfied: google-pasta>=0.1.1 in /opt/conda/lib/python3.7/site-packages (from tensorflow==2.9.0->-r requirements.txt (line 19)) (0.2.0)\nRequirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /opt/conda/lib/python3.7/site-packages (from tensorflow==2.9.0->-r requirements.txt (line 19)) (0.29.0)\nRequirement already satisfied: astunparse>=1.6.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow==2.9.0->-r requirements.txt (line 19)) (1.6.3)\nCollecting keras<2.10.0,>=2.9.0rc0\n  Downloading keras-2.9.0-py2.py3-none-any.whl (1.6 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m66.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: typing-extensions>=3.6.6 in /opt/conda/lib/python3.7/site-packages (from tensorflow==2.9.0->-r requirements.txt (line 19)) (4.4.0)\nRequirement already satisfied: opt-einsum>=2.3.2 in /opt/conda/lib/python3.7/site-packages (from tensorflow==2.9.0->-r requirements.txt (line 19)) (3.3.0)\nRequirement already satisfied: cachetools<5.0,>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from google-auth<3,>=1.6.3->tensorboard==2.9.1->-r requirements.txt (line 18)) (4.2.4)\nRequirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.7/site-packages (from google-auth<3,>=1.6.3->tensorboard==2.9.1->-r requirements.txt (line 18)) (4.9)\nRequirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.7/site-packages (from google-auth<3,>=1.6.3->tensorboard==2.9.1->-r requirements.txt (line 18)) (0.2.8)\nRequirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.7/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard==2.9.1->-r requirements.txt (line 18)) (1.3.1)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard==2.9.1->-r requirements.txt (line 18)) (1.26.14)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard==2.9.1->-r requirements.txt (line 18)) (2.1.1)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard==2.9.1->-r requirements.txt (line 18)) (3.4)\nRequirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/lib/python3.7/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard==2.9.1->-r requirements.txt (line 18)) (0.4.8)\nRequirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.7/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard==2.9.1->-r requirements.txt (line 18)) (3.2.2)\nBuilding wheels for collected packages: progress\n  Building wheel for progress (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for progress: filename=progress-1.6-py3-none-any.whl size=9630 sha256=48df6624ad950171eca26b47eaa64b4e5e3ece270b9c6ebcb4bff44a72e8b883\n  Stored in directory: /root/.cache/pip/wheels/07/17/ad/9088d33fe3c8802d1587653472d89f833407f6ee1b8428d99f\nSuccessfully built progress\nInstalling collected packages: progress, keras, flatbuffers, Werkzeug, tf-slim, tensorflow-estimator, six, protobuf, Markdown, h5py, astor, mock, Keras-Preprocessing, Keras-Applications, tensorboard, tensorflow\n  Attempting uninstall: keras\n    Found existing installation: keras 2.11.0\n    Uninstalling keras-2.11.0:\n      Successfully uninstalled keras-2.11.0\n  Attempting uninstall: flatbuffers\n    Found existing installation: flatbuffers 23.1.21\n    Uninstalling flatbuffers-23.1.21:\n      Successfully uninstalled flatbuffers-23.1.21\n  Attempting uninstall: Werkzeug\n    Found existing installation: Werkzeug 2.2.3\n    Uninstalling Werkzeug-2.2.3:\n      Successfully uninstalled Werkzeug-2.2.3\n  Attempting uninstall: tensorflow-estimator\n    Found existing installation: tensorflow-estimator 2.11.0\n    Uninstalling tensorflow-estimator-2.11.0:\n      Successfully uninstalled tensorflow-estimator-2.11.0\n  Attempting uninstall: six\n    Found existing installation: six 1.16.0\n    Uninstalling six-1.16.0:\n      Successfully uninstalled six-1.16.0\n  Attempting uninstall: protobuf\n    Found existing installation: protobuf 3.20.3\n    Uninstalling protobuf-3.20.3:\n      Successfully uninstalled protobuf-3.20.3\n  Attempting uninstall: Markdown\n    Found existing installation: Markdown 3.4.1\n    Uninstalling Markdown-3.4.1:\n      Successfully uninstalled Markdown-3.4.1\n  Attempting uninstall: h5py\n    Found existing installation: h5py 3.8.0\n    Uninstalling h5py-3.8.0:\n      Successfully uninstalled h5py-3.8.0\n  Attempting uninstall: mock\n    Found existing installation: mock 5.0.1\n    Uninstalling mock-5.0.1:\n      Successfully uninstalled mock-5.0.1\n  Attempting uninstall: tensorboard\n    Found existing installation: tensorboard 2.11.2\n    Uninstalling tensorboard-2.11.2:\n      Successfully uninstalled tensorboard-2.11.2\n  Attempting uninstall: tensorflow\n    Found existing installation: tensorflow 2.11.0\n    Uninstalling tensorflow-2.11.0:\n      Successfully uninstalled tensorflow-2.11.0\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ndask-cudf 21.12.2 requires cupy-cuda115, which is not installed.\ncudf 21.12.2 requires cupy-cuda115, which is not installed.\ntfx-bsl 1.12.0 requires google-api-python-client<2,>=1.7.11, but you have google-api-python-client 2.83.0 which is incompatible.\ntfx-bsl 1.12.0 requires pyarrow<7,>=6, but you have pyarrow 5.0.0 which is incompatible.\ntfx-bsl 1.12.0 requires tensorflow<3,>=2.11, but you have tensorflow 2.9.0 which is incompatible.\ntensorflow-transform 1.12.0 requires pyarrow<7,>=6, but you have pyarrow 5.0.0 which is incompatible.\ntensorflow-transform 1.12.0 requires tensorflow<2.12,>=2.11.0, but you have tensorflow 2.9.0 which is incompatible.\ntensorflow-text 2.11.0 requires tensorflow<2.12,>=2.11.0; platform_machine != \"arm64\" or platform_system != \"Darwin\", but you have tensorflow 2.9.0 which is incompatible.\ntensorflow-serving-api 2.11.0 requires tensorflow<3,>=2.11.0, but you have tensorflow 2.9.0 which is incompatible.\ntensorflow-decision-forests 1.2.0 requires tensorflow~=2.11.0, but you have tensorflow 2.9.0 which is incompatible.\nonnx 1.13.1 requires protobuf<4,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\nflask 2.2.3 requires Werkzeug>=2.2.2, but you have werkzeug 1.0.1 which is incompatible.\ndask-cudf 21.12.2 requires dask<=2021.11.2,>=2021.11.1, but you have dask 2022.2.0 which is incompatible.\ncloud-tpu-client 0.10 requires google-api-python-client==1.8.0, but you have google-api-python-client 2.83.0 which is incompatible.\nboto3 1.26.100 requires botocore<1.30.0,>=1.29.100, but you have botocore 1.27.59 which is incompatible.\napache-beam 2.44.0 requires dill<0.3.2,>=0.3.1.1, but you have dill 0.3.6 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed Keras-Applications-1.0.8 Keras-Preprocessing-1.1.2 Markdown-3.1.1 Werkzeug-1.0.1 astor-0.8.1 flatbuffers-1.12 h5py-3.1.0 keras-2.9.0 mock-3.0.5 progress-1.6 protobuf-3.19.6 six-1.16.0 tensorboard-2.9.1 tensorflow-2.9.0 tensorflow-estimator-2.9.0 tf-slim-1.1.0\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"!cd '/kaggle/working/DeepIRT-tf2' && mkdir logs","metadata":{"execution":{"iopub.status.busy":"2023-04-08T19:15:24.494129Z","iopub.execute_input":"2023-04-08T19:15:24.494550Z","iopub.status.idle":"2023-04-08T19:15:25.441656Z","shell.execute_reply.started":"2023-04-08T19:15:24.494489Z","shell.execute_reply":"2023-04-08T19:15:25.440354Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"!cd '/kaggle/working/DeepIRT-tf2' && python3 main.py --dataset ednet_s300","metadata":{"execution":{"iopub.status.busy":"2023-04-08T19:15:28.890041Z","iopub.execute_input":"2023-04-08T19:15:28.891297Z","iopub.status.idle":"2023-04-09T04:36:23.863884Z","shell.execute_reply.started":"2023-04-08T19:15:28.891238Z","shell.execute_reply":"2023-04-09T04:36:23.862462Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"2023-04-08 19:15:33,371 - Deep-IRT-model - INFO - Model Config: Namespace(batch_size=32, checkpoint_dir='./models/ednet_s300/b32_m50_q50_qa100_f50/2023-04-08T1915', cpu=False, data_dir='/kaggle/input/top-300', data_name='Top_300_questions_seq', dataset='ednet_s300', key_memory_state_dim=50, learning_rate=0.003, max_grad_norm=10.0, memory_size=50, n_epochs=10, n_questions=300, result_log_dir='./results/ednet_s300/b32_m50_q50_qa100_f50/2023-04-08T1915', resume='', save=True, seq_len=200, show=True, summary_vector_output_dim=50, tensorboard_dir='./tensorboard/ednet_s300/b32_m50_q50_qa100_f50/2023-04-08T1915', train=True, use_ogive_model=False, value_memory_state_dim=100)\n2023-04-08 19:15:33,372 - Deep-IRT-model - INFO - Cross Validation 1\n2023-04-08 19:15:35,331 - Deep-IRT-model - INFO - Initializing Placeholder\n2023-04-08 19:15:35,333 - Deep-IRT-model - INFO - Initializing Key and Value Memory\n2023-04-08 19:15:35,351 - Deep-IRT-model - INFO - Initializing Q and QA Embedding\n2023-04-08 19:15:35,362 - Deep-IRT-model - INFO - Initializing Embedding Lookup\n2023-04-08 19:15:35,370 - Deep-IRT-model - INFO - Initializing Influence Procedure\n/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer_v1.py:1694: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n  warnings.warn('`layer.apply` is deprecated and '\n2023-04-08 19:15:44,901 - Deep-IRT-model - INFO - Initializing Loss Function\n2023-04-08 19:16:07,216 - Deep-IRT-model - INFO - Memory/key_memory_matrix:0 (float32_ref 50x50) [2500, bytes: 10000]\nMemory/value_memory_matrix:0 (float32_ref 50x100) [5000, bytes: 20000]\nEmbedding/q_embed:0 (float32_ref 301x50) [15050, bytes: 60200]\nEmbedding/qa_embed:0 (float32_ref 601x100) [60100, bytes: 240400]\nDKVMN-ValueHead/EraseOperation/weights:0 (float32_ref 100x100) [10000, bytes: 40000]\nDKVMN-ValueHead/EraseOperation/biases:0 (float32_ref 100) [100, bytes: 400]\nDKVMN-ValueHead/AddOperation/weights:0 (float32_ref 100x100) [10000, bytes: 40000]\nDKVMN-ValueHead/AddOperation/biases:0 (float32_ref 100) [100, bytes: 400]\nSummaryOperation/weights:0 (float32_ref 150x50) [7500, bytes: 30000]\nSummaryOperation/biases:0 (float32_ref 50) [50, bytes: 200]\nStudentAbilityOutputLayer/weights:0 (float32_ref 50x1) [50, bytes: 200]\nStudentAbilityOutputLayer/biases:0 (float32_ref 1) [1, bytes: 4]\nQuestionDifficultyOutputLayer/weights:0 (float32_ref 50x1) [50, bytes: 200]\nQuestionDifficultyOutputLayer/biases:0 (float32_ref 1) [1, bytes: 4]\nTotal size of variables: 110502 \nTotal bytes of variables: 442008 \n\n2023-04-08 19:16:08,221 - Deep-IRT-model - INFO - Reading /kaggle/input/top-300/Top_300_questions_seq_train.csv and /kaggle/input/top-300/Top_300_questions_seq_valid.csv\ntrain |================================| 100.0% | Elapsed: 2182s | ETA: 0s   \nvalid |================================| 100.0% | Elapsed: 984s | ETA: 0s   \n\u001b[?25h2023-04-08 20:09:58,247 - Deep-IRT-model - INFO - \n[Epoch 1/10] Training result:      AUC: 73.55%\t Acc: 67.18%\t Loss: 7.5561\n[[3798142 2069247]\n [1903748 4335822]]\n[Epoch 1/10] Validation result:    AUC: 69.97%\t Acc: 64.54%\t Loss: 8.1647\n[[1529497 1125818]\n [ 861159 2087142]]\n2023-04-08 20:10:00,777 - Deep-IRT-model - INFO - Model improved. Save model to ./models/ednet_s300/b32_m50_q50_qa100_f50/2023-04-08T1915/ep001-auc70-acc65/Deep-IRT\ntrain |================================| 100.0% | Elapsed: 2240s | ETA: 0s   \nvalid |================================| 100.0% | Elapsed: 1044s | ETA: 0s  \n\u001b[?25h2023-04-08 21:05:16,191 - Deep-IRT-model - INFO - \n[Epoch 2/10] Training result:      AUC: 74.44%\t Acc: 67.97%\t Loss: 7.3758\n[[3859080 2008116]\n [1869961 4369391]]\n[Epoch 2/10] Validation result:    AUC: 70.31%\t Acc: 64.87%\t Loss: 8.0895\n[[1528275 1127050]\n [ 841600 2106629]]\n2023-04-08 21:05:18,402 - Deep-IRT-model - INFO - Model improved. Save model to ./models/ednet_s300/b32_m50_q50_qa100_f50/2023-04-08T1915/ep002-auc70-acc65/Deep-IRT\ntrain |================================| 100.0% | Elapsed: 2256s | ETA: 0s   \nvalid |================================| 100.0% | Elapsed: 1038s | ETA: 0s  \n\u001b[?25h2023-04-08 22:00:44,858 - Deep-IRT-model - INFO - \n[Epoch 3/10] Training result:      AUC: 74.63%\t Acc: 68.13%\t Loss: 7.3378\n[[3876714 1990479]\n [1867569 4371745]]\n[Epoch 3/10] Validation result:    AUC: 70.30%\t Acc: 64.70%\t Loss: 8.1285\n[[1610547 1044871]\n [ 933377 2015035]]\ntrain |================================| 100.0% | Elapsed: 2224s | ETA: 0s   \nvalid |================================| 100.0% | Elapsed: 1039s | ETA: 0s  \n\u001b[?25h2023-04-08 22:55:39,595 - Deep-IRT-model - INFO - \n[Epoch 4/10] Training result:      AUC: 74.70%\t Acc: 68.19%\t Loss: 7.3247\n[[3884238 1982964]\n [1868205 4371120]]\n[Epoch 4/10] Validation result:    AUC: 70.43%\t Acc: 64.88%\t Loss: 8.0859\n[[1672328  983033]\n [ 984771 1963502]]\n2023-04-08 22:55:41,832 - Deep-IRT-model - INFO - Model improved. Save model to ./models/ednet_s300/b32_m50_q50_qa100_f50/2023-04-08T1915/ep004-auc70-acc65/Deep-IRT\ntrain |================================| 100.0% | Elapsed: 2234s | ETA: 0s   \nvalid |================================| 100.0% | Elapsed: 1062s | ETA: 0s  \n\u001b[?25h2023-04-08 23:51:09,827 - Deep-IRT-model - INFO - \n[Epoch 5/10] Training result:      AUC: 74.76%\t Acc: 68.25%\t Loss: 7.3105\n[[3894712 1972390]\n [1871288 4368100]]\n[Epoch 5/10] Validation result:    AUC: 70.48%\t Acc: 64.82%\t Loss: 8.0996\n[[1783925  871413]\n [1099717 1848578]]\ntrain |================================| 100.0% | Elapsed: 2238s | ETA: 0s   \nvalid |================================| 100.0% | Elapsed: 1070s | ETA: 0s  \n\u001b[?25h2023-04-09 00:46:49,536 - Deep-IRT-model - INFO - \n[Epoch 6/10] Training result:      AUC: 74.78%\t Acc: 68.27%\t Loss: 7.3061\n[[3898191 1969172]\n [1872327 4367196]]\n[Epoch 6/10] Validation result:    AUC: 70.07%\t Acc: 64.48%\t Loss: 8.1782\n[[1677615  977731]\n [1012550 1935795]]\ntrain |================================| 100.0% | Elapsed: 2249s | ETA: 0s   \nvalid |================================| 100.0% | Elapsed: 1103s | ETA: 0s  \n\u001b[?25h2023-04-09 01:43:13,058 - Deep-IRT-model - INFO - \n[Epoch 7/10] Training result:      AUC: 74.80%\t Acc: 68.27%\t Loss: 7.3058\n[[3899807 1967353]\n [1873827 4365357]]\n[Epoch 7/10] Validation result:    AUC: 70.42%\t Acc: 64.95%\t Loss: 8.0696\n[[1608002 1047398]\n [ 916491 2031895]]\n2023-04-09 01:43:15,250 - Deep-IRT-model - INFO - Model improved. Save model to ./models/ednet_s300/b32_m50_q50_qa100_f50/2023-04-08T1915/ep007-auc70-acc65/Deep-IRT\ntrain |================================| 100.0% | Elapsed: 2276s | ETA: 0s   \nvalid |================================| 100.0% | Elapsed: 1136s | ETA: 0s  \n\u001b[?25h2023-04-09 02:40:39,839 - Deep-IRT-model - INFO - \n[Epoch 8/10] Training result:      AUC: 74.81%\t Acc: 68.27%\t Loss: 7.3065\n[[3897715 1969503]\n [1872116 4367262]]\n[Epoch 8/10] Validation result:    AUC: 70.00%\t Acc: 64.58%\t Loss: 8.1561\n[[1601967 1053445]\n [ 931503 2016909]]\ntrain |================================| 100.0% | Elapsed: 2258s | ETA: 0s   \nvalid |================================| 100.0% | Elapsed: 1158s | ETA: 0s  \n\u001b[?25h2023-04-09 03:38:07,294 - Deep-IRT-model - INFO - \n[Epoch 9/10] Training result:      AUC: 74.82%\t Acc: 68.28%\t Loss: 7.3031\n[[3897287 1970117]\n [1869829 4369747]]\n[Epoch 9/10] Validation result:    AUC: 70.44%\t Acc: 64.96%\t Loss: 8.0679\n[[1664799  990491]\n [ 972884 1975325]]\n2023-04-09 03:38:09,558 - Deep-IRT-model - INFO - Model improved. Save model to ./models/ednet_s300/b32_m50_q50_qa100_f50/2023-04-08T1915/ep009-auc70-acc65/Deep-IRT\ntrain |================================| 100.0% | Elapsed: 2290s | ETA: 0s   \nvalid |================================| 100.0% | Elapsed: 1170s | ETA: 0s  \n\u001b[?25h2023-04-09 04:36:21,209 - Deep-IRT-model - INFO - \n[Epoch 10/10] Training result:      AUC: 74.82%\t Acc: 68.30%\t Loss: 7.3002\n[[3902224 1965082]\n [1873288 4366232]]\n[Epoch 10/10] Validation result:    AUC: 70.38%\t Acc: 64.90%\t Loss: 8.0816\n[[1647826 1007581]\n [ 959229 1989156]]\n2023-04-09 04:36:21,212 - Deep-IRT-model - INFO - Best result at epoch 9: AUC: 70.44\t Accuracy: 64.96\t Loss: 8.0679\n2023-04-09 04:36:21,452 - Deep-IRT-model - INFO - Cross Validation Result:\nAUC: 70.44 +/- 0.00\nAccuracy: 64.96 +/- 0.00\nLoss: 8.07 +/- 0.00\n\n","output_type":"stream"}]}]}